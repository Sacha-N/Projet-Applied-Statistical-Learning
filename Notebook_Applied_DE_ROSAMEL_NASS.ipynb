{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb09aad",
   "metadata": {},
   "source": [
    "# Applied Statistical Learning - Prédiction de la durée de mise en chantier en France\n",
    "Dans le cadre de ce projet, nous avons exploité les données du fichier SITADEL, qui recense de manière exhaustive l'ensemble des permis de construire en France. Pour avoir un échantillon homogène, nous nous sommes concentrés sur la période 2015-2019 (i.e. avant les délais liés au Covid). Nous avons enrichi notre fichier à l'aide de deux sources externes: le fichier complet de l'Insee, agrégeant des données en open data pour l'ensemble des communes, ainsi que la grille de densité des communes de l'Insee. \n",
    "Pour faciliter la réplication de nos résultats, nous avons déposé nos données brutes sur une dropbox (1.5Go) : https://www.dropbox.com/scl/fo/b3dw5eht79785mrg7uueq/APQ7m21mQcsZzh7Uy7ASj6k?rlkey=rutboi86sxni30nqg6lzsycqh&st=n60gni1d&dl=0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dcffa",
   "metadata": {},
   "source": [
    "# 1. Mise en place des chemins\n",
    "Pour faire tourner l'ensemble du code de ce notebook, il est nécessaire de placer l'ensemble des fichiers de la dropbox dans un dossier data, puis d'adapter le chemin ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8319cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (2025.12.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from fastparquet) (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from fastparquet) (2.3.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from fastparquet) (2025.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\nasss\\documents\\projet-applied-statistical-learning\\.venv\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# CHEMIN A ADAPTER\n",
    "chemin_data = Path(\"data\")   # mettre le chemin local vers le dossier data avec les fichiers de la dropbox\n",
    "\n",
    "# Suffixes fixes\n",
    "chemin_autorisation = chemin_data / \"Liste-des-autorisations-durbanisme-creant-des-logements.2025-10.csv\"\n",
    "chemin_grilles = chemin_data / \"grille_densite_7_niveaux_2019.xlsx\"\n",
    "chemin_dossier = chemin_data / \"dossier_complet.csv\"\n",
    "\n",
    "# installer pyarrow pour lire les fichiers parquet, et openpyxl pour lire les fichiers excel\n",
    "%pip install pyarrow fastparquet\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bf53f",
   "metadata": {},
   "source": [
    "# 2. Chargement des données\n",
    "Ce premier chunk permet de sélectionner nos variables d'intérêt, et d'observer notre base avant tout filtre. Le fichier contient initialement 1,8 million de permis de construire, couvrant souvent plusieurs logements. Plusieurs variables d'intérêt sont possibles : la durée avant l'obtention de l'autorisation, la durée entre l'obtention de l'autorisation et la mise en chantier, ou la durée du chantier. Afin d'éviter de nous restreindre à des chantiers terminés, nous étudierons la **durée de mise en chantier**. Après le retrait de durées absentes ou négatives, nous avons 1,7 million de permis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28025f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasss\\AppData\\Local\\Temp\\ipykernel_16544\\114887618.py:68: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATE_REELLE_AUTORISATION:\n",
      "  Type: object\n",
      "  Sample values:\n",
      "['20/09/2013', '30/09/2013', '20/09/2013', '16/11/2013', '06/12/2013', '09/04/2014', '27/08/2014', '04/09/2014', '08/10/2014', '14/04/2015']\n",
      "  Null count: 0\n",
      "\n",
      "DATE_REELLE_DOC:\n",
      "  Type: object\n",
      "  Sample values:\n",
      "['26/11/2013', '06/12/2013', '26/11/2013', '24/01/2014', '12/03/2014', '16/06/2014', '02/09/2014', nan, '26/10/2015', nan]\n",
      "  Null count: 563692\n",
      "\n",
      "DPC_AUT:\n",
      "  Type: object\n",
      "  Sample values:\n",
      "['2013-11', '2013-10', '2013-11', '2013-11', '2013-12', '2014-04', '2014-08', '2014-09', '2014-10', '2017-11']\n",
      "  Null count: 5\n",
      "\n",
      "DATE_REELLE_DAACT:\n",
      "  Type: object\n",
      "  Sample values:\n",
      "[nan, '08/08/2014', '27/06/2014', '09/04/2014', '14/11/2014', nan, nan, nan, nan, nan]\n",
      "  Null count: 1143994\n",
      "\n",
      "DPC_PREM:\n",
      "  Type: object\n",
      "  Sample values:\n",
      "['2013-08', '2013-08', '2013-09', '2013-10', '2013-11', '2014-03', '2014-08', '2014-09', '2014-08', '2015-04']\n",
      "  Null count: 15\n",
      "Df shape avant: (1827973, 59)\n",
      "Nombre de lignes dans le df original: 1827973\n",
      "\n",
      " Après nettoyages :\n",
      "Lignes avec delai_ouverture_chantier non-NA: 1243443\n",
      "Lignes avec duree_travaux non-NA: 681541\n",
      "Lignes avec duree_obtiention_autorisation non-NA: 1596233\n",
      "Lignes avec duree_obtiention_autorisation non-0: 1596233\n",
      "\n",
      "Shape du df nettoyé : (1747808, 64)\n",
      "Nombre de lignes dans le df nettoyé : 1747808\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Chargement de Sitadel\n",
    "# Chemin : défini en amont, vérifier que le chunk a bien été executé. \n",
    "\n",
    "# 1.1 Exclusion ex ante des colonnes non pertinentes\n",
    "all_cols = pd.read_csv(chemin_autorisation, sep=\";\", skiprows=1, nrows=1).columns.tolist()\n",
    "\n",
    "vars_mai2022 = [ #On retire les colonnes qui n'existent qu'à partir de mai 2022 (car on veut un dataset homogène dans le temps)\n",
    "    \"AN_DEPOT\",  # \"DPC_PREM\", (theoriquement il faudrait la retirer, mais bon)\n",
    "    \"NATURE_PROJET_COMPLETEE\",\n",
    "    \"DESTINATION_PRINCIPALE\",\n",
    "    \"TYPE_PRINCIP_LOGTS_CREES\",\n",
    "    \"TYPE_TRANSFO_PRINCIPAL\",\n",
    "    \"TYPE_PRINCIP_LOCAUX_TRANSFORMES\",\n",
    "    \"I_PISCINE\",\n",
    "    \"I_GARAGE\",\n",
    "    \"I_VERANDA\",\n",
    "    \"I_ABRI_JARDIN\",\n",
    "    \"I_AUTRE_ANNEXE\",\n",
    "    \"RES_PERS_AGEES\",\n",
    "    \"RES_ETUDIANTS\",\n",
    "    \"RES_TOURISME\",\n",
    "    \"RES_HOTEL_SOCIALE\",\n",
    "    \"RES_SOCIALE\",\n",
    "    \"RES_HANDICAPES\",\n",
    "    \"RES_AUTRE\",\n",
    "    \"NB_LGT_INDIV_PURS\",\n",
    "    \"NB_LGT_INDIV_GROUPES\",\n",
    "    \"NB_LGT_RES\",\n",
    "    \"NB_LGT_COL_HORS_RES\",\n",
    "    \"SUgbr_HEB_TRANSFORMEE\",\n",
    "    \"SUgbr_BUR_TRANSFORMEE\",\n",
    "    \"SUgbr_COM_TRANSFORMEE\",\n",
    "    \"SUgbr_ART_TRANSFORMEE\",\n",
    "    \"SUgbr_IND_TRANSFORMEE\",\n",
    "    \"SUgbr_AGR_TRANSFORMEE\",\n",
    "    \"SURF_ENT_TRANSFORMEE\",\n",
    "    \"SURF_PUB_TRANSFORMEE\",\n",
    "]\n",
    "vars_non_pertinentes = [ # on retire les variables sans pouvoir prédictif (ex : SIREN du demandeur)\n",
    "    \"Num_DAU\",\n",
    "    \"SIREN_DEM\",\n",
    "    \"SIRET_DEM\",\n",
    "    \"DENOM_DEM\",\n",
    "    \"CODPOST_DEM\",\n",
    "    \"LOCALITE_DEM\",\n",
    "    \"ADR_NUM_TER\",\n",
    "    \"ADR_TYPEVOIE_TER\",\n",
    "    \"ADR_LIBVOIE_TER\",\n",
    "    \"ADR_LIEUDIT_TER\",\n",
    "    \"ADR_LOCALITE_TER\",\n",
    "    \"ADR_CODPOST_TER\",\n",
    "    \"SEC_CADASTRE1\",\n",
    "    \"NUM_CADASTRE1\",\n",
    "    \"SEC_CADASTRE2\",\n",
    "    \"NUM_CADASTRE2\",\n",
    "    \"SEC_CADASTRE3\",\n",
    "    \"NUM_CADASTRE3\",\n",
    "]\n",
    "\n",
    "cols_to_drop = set(vars_mai2022 + vars_non_pertinentes)\n",
    "use_cols = [c for c in all_cols if c not in cols_to_drop]\n",
    "\n",
    "# 1.2 Chargement avec les colonnes filtrées\n",
    "df = pd.read_csv(\n",
    "    chemin_autorisation,\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8\",\n",
    "    skiprows=1,\n",
    "    usecols=use_cols\n",
    ")\n",
    "\n",
    "# 3. Etudions nos dates\n",
    "date_cols = [\n",
    "    \"DATE_REELLE_AUTORISATION\",\n",
    "    \"DATE_REELLE_DOC\",\n",
    "    \"DPC_AUT\",\n",
    "    \"DATE_REELLE_DAACT\",\n",
    "    \"DPC_PREM\",\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Type: {df[col].dtype}\")\n",
    "        print(\"  Sample values:\")\n",
    "        print(df[col].head(10).tolist())\n",
    "        print(f\"  Null count: {df[col].isna().sum()}\")\n",
    "    else:\n",
    "        print(f\"\\n{col}: NOT FOUND in dataframe\")\n",
    "\n",
    "\n",
    "## Puis, nettoyons le dataset\n",
    "def nettoyer_dataset(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Conversion des dates en datetime\n",
    "    # 3 dates en format DD/MM/YYYY\n",
    "    dmY_cols = [\"DATE_REELLE_AUTORISATION\", \"DATE_REELLE_DOC\", \"DATE_REELLE_DAACT\"]\n",
    "    for col in dmY_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(\n",
    "                df[col], errors=\"coerce\", dayfirst=True\n",
    "            )\n",
    "\n",
    "    # 2 dates en format YYYY-MM\n",
    "    for col in [\"DPC_AUT\", \"DPC_PREM\"]:\n",
    "        if col in df.columns:\n",
    "            # on impose un format\n",
    "            df[col] = pd.to_datetime(\n",
    "                df[col].astype(str).str.strip(), errors=\"coerce\", format=\"%Y-%m\"\n",
    "            )\n",
    "\n",
    "    # On retire les dates fausses\n",
    "    min_date = pd.Timestamp(\"1900-01-01\") \n",
    "    max_date = pd.Timestamp(\"2025-12-31\")\n",
    "    for col in dmY_cols + [\"DPC_AUT\", \"DPC_PREM\"]:\n",
    "        if col in df.columns:\n",
    "            mask = (df[col] < min_date) | (df[col] > max_date)\n",
    "            df.loc[mask, col] = pd.NaT\n",
    "\n",
    "    # On construit trois variables cibles, même si in fine on n'utilisera que delai_ouverture_chantier\n",
    "    # Nous avons laissé notre code car nous avions essayé avec d'autres variables cibles, finalement moins faciles à prédire.\n",
    "    if \"DATE_REELLE_AUTORISATION\" in df.columns and \"DATE_REELLE_DOC\" in df.columns:\n",
    "        mask = df[\"DATE_REELLE_AUTORISATION\"].notna() & df[\"DATE_REELLE_DOC\"].notna()\n",
    "        df.loc[mask, \"delai_ouverture_chantier\"] = (\n",
    "            df.loc[mask, \"DATE_REELLE_DOC\"] - df.loc[mask, \"DATE_REELLE_AUTORISATION\"]\n",
    "        ).dt.days\n",
    "\n",
    "    if \"DATE_REELLE_DAACT\" in df.columns and \"DATE_REELLE_DOC\" in df.columns:\n",
    "        mask = df[\"DATE_REELLE_DAACT\"].notna() & df[\"DATE_REELLE_DOC\"].notna()\n",
    "        df.loc[mask, \"duree_travaux\"] = (\n",
    "            df.loc[mask, \"DATE_REELLE_DAACT\"] - df.loc[mask, \"DATE_REELLE_DOC\"]\n",
    "        ).dt.days\n",
    "\n",
    "    if \"DPC_AUT\" in df.columns and \"DPC_PREM\" in df.columns:\n",
    "        mask = df[\"DPC_PREM\"].notna() & df[\"DPC_AUT\"].notna()\n",
    "        df.loc[mask, \"duree_obtiention_autorisation\"] = (\n",
    "            df.loc[mask, \"DPC_AUT\"] - df.loc[mask, \"DPC_PREM\"]\n",
    "        ).dt.days\n",
    "\n",
    "    # On traite les variables cibles: conversion en numérique et suppression des valeurs négatives\n",
    "    duration_cols = [\n",
    "        \"delai_ouverture_chantier\",\n",
    "        \"duree_travaux\",\n",
    "        \"duree_obtiention_autorisation\",\n",
    "    ]\n",
    "    for col in duration_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            df.loc[df[col] <= 0, col] = pd.NA\n",
    "\n",
    "    # Suppression des lignes sans cibles valides (NA, null, zero or negative)\n",
    "    existing_duration_cols = [c for c in duration_cols if c in df.columns]\n",
    "    df = df.dropna(subset=existing_duration_cols, how=\"all\")\n",
    "    \n",
    "    # On crée mois et année\n",
    "    df[\"annee_autorisation\"] = df[\"DATE_REELLE_AUTORISATION\"].dt.year\n",
    "    df[\"mois_autorisation\"] = df[\"DATE_REELLE_AUTORISATION\"].dt.month\n",
    "    return df\n",
    "\n",
    "\n",
    "df_clean = nettoyer_dataset(df)\n",
    "\n",
    "# On règle également les codes (dep, commune, région)\n",
    "colonnes_codes = [\n",
    "    \"DEP_CODE\",\n",
    "    \"COMM\",\n",
    "    \"CODGEO\",\n",
    "    \"REG_CODE\"\n",
    "]\n",
    "\n",
    "for col in colonnes_codes:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].astype(\"string\")\n",
    "\n",
    "# On enregistre en parquet pour conserver les formats\n",
    "df_clean.to_parquet(\n",
    "    chemin_data / \"autorisations.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "## 4. Comparaison\n",
    "# Avant nettoyage\n",
    "print(\"Df shape avant:\", df.shape)\n",
    "print(\"Nombre de lignes dans le df original:\", len(df))\n",
    "\n",
    "# Après nettoyage\n",
    "print(\"\\n Après nettoyages :\")\n",
    "print(\n",
    "    \"Lignes avec delai_ouverture_chantier non-NA:\",\n",
    "    df_clean[\"delai_ouverture_chantier\"].notna().sum(),\n",
    ")\n",
    "print(\"Lignes avec duree_travaux non-NA:\", df_clean[\"duree_travaux\"].notna().sum())\n",
    "print(\n",
    "    \"Lignes avec duree_obtiention_autorisation non-NA:\",\n",
    "    df_clean[\"duree_obtiention_autorisation\"].notna().sum(),\n",
    ")\n",
    "print(\n",
    "    \"Lignes avec duree_obtiention_autorisation non-0:\",\n",
    "    (\n",
    "        df_clean[\"duree_obtiention_autorisation\"].notna()\n",
    "        & (df_clean[\"duree_obtiention_autorisation\"] != 0)\n",
    "    ).sum(),\n",
    ")\n",
    "print(\"\\nShape du df nettoyé :\", df_clean.shape)\n",
    "print(\"Nombre de lignes dans le df nettoyé :\", len(df_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531e9f0",
   "metadata": {},
   "source": [
    "# 3. Filtre et enrichissement des données\n",
    "Avec SITADEL, nous avons des données relatives au projet de construction (caractéristiques du demandeur, caractéristiques du projet), mais nous n'avons aucune information sur l'environnement territorial, à l'exception du code commune-département-région. Par appariement à l'aide du code commune, nous ajoutons donc la grille de densité qui nous renseigne sur le type d'occupation du sol (centre urbanisé, rural dense, rural peu dense, ...) et la population communale. Nous ajoutons également des données socio-démographiques du dossier complet : taux de pauvreté communal, part de ménages imposés, nombre de résidences secondaires, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74de567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1747808 entries, 0 to 1747807\n",
      "Data columns (total 64 columns):\n",
      " #   Column                         Dtype         \n",
      "---  ------                         -----         \n",
      " 0   REG_CODE                       string        \n",
      " 1   REG_LIBELLE                    object        \n",
      " 2   DEP_CODE                       string        \n",
      " 3   DEP_LIBELLE                    object        \n",
      " 4   COMM                           string        \n",
      " 5   TYPE_DAU                       object        \n",
      " 6   NUM_DAU                        object        \n",
      " 7   ETAT_DAU                       int64         \n",
      " 8   DATE_REELLE_AUTORISATION       datetime64[ns]\n",
      " 9   DATE_REELLE_DOC                datetime64[ns]\n",
      " 10  DATE_REELLE_DAACT              datetime64[ns]\n",
      " 11  DPC_PREM                       datetime64[ns]\n",
      " 12  DPC_AUT                        datetime64[ns]\n",
      " 13  DPC_DOC                        object        \n",
      " 14  DPC_DERN                       object        \n",
      " 15  CAT_DEM                        int64         \n",
      " 16  APE_DEM                        object        \n",
      " 17  CJ_DEM                         float64       \n",
      " 18  REC_ARCHI                      bool          \n",
      " 19  SUPERFICIE_TERRAIN             int64         \n",
      " 20  ZONE_OP                        int64         \n",
      " 21  NATURE_PROJET_DECLAREE         int64         \n",
      " 22  I_EXTENSION                    bool          \n",
      " 23  I_SURELEVATION                 bool          \n",
      " 24  I_NIVSUPP                      bool          \n",
      " 25  NB_NIV_MAX                     int64         \n",
      " 26  UTILISATION                    int64         \n",
      " 27  RES_PRINCIP_OU_SECOND          int64         \n",
      " 28  TYP_ANNEXE                     int64         \n",
      " 29  RESIDENCE                      int64         \n",
      " 30  NB_LGT_TOT_CREES               int64         \n",
      " 31  NB_LGT_IND_CREES               int64         \n",
      " 32  NB_LGT_COL_CREES               int64         \n",
      " 33  NB_LGT_DEMOLIS                 int64         \n",
      " 34  NB_LGT_1P                      int64         \n",
      " 35  NB_LGT_2P                      int64         \n",
      " 36  NB_LGT_3P                      int64         \n",
      " 37  NB_LGT_4P                      int64         \n",
      " 38  NB_LGT_5P                      int64         \n",
      " 39  NB_LGT_6P_PLUS                 int64         \n",
      " 40  NB_LGT_PRET_LOC_SOCIAL         int64         \n",
      " 41  NB_LGT_ACC_SOC_HORS_PTZ        int64         \n",
      " 42  NB_LGT_PTZ                     int64         \n",
      " 43  SURF_HAB_AVANT                 int64         \n",
      " 44  SURF_HAB_CREEE                 int64         \n",
      " 45  SURF_HAB_ISSUE_TRANSFO         int64         \n",
      " 46  SURF_HAB_DEMOLIE               int64         \n",
      " 47  SURF_HAB_TRANSFORMEE           int64         \n",
      " 48  SURF_LOC_AVANT                 int64         \n",
      " 49  SURF_LOC_CREEE                 int64         \n",
      " 50  SURF_LOC_ISSUE_TRANSFO         int64         \n",
      " 51  SURF_LOC_DEMOLIE               int64         \n",
      " 52  SURF_LOC_TRANSFORMEE           int64         \n",
      " 53  SURF_HEB_TRANSFORMEE           int64         \n",
      " 54  SURF_BUR_TRANSFORMEE           int64         \n",
      " 55  SURF_COM_TRANSFORMEE           int64         \n",
      " 56  SURF_ART_TRANSFORMEE           int64         \n",
      " 57  SURF_IND_TRANSFORMEE           int64         \n",
      " 58  SURF_AGR_TRANSFORMEE           int64         \n",
      " 59  delai_ouverture_chantier       float64       \n",
      " 60  duree_travaux                  float64       \n",
      " 61  duree_obtiention_autorisation  float64       \n",
      " 62  annee_autorisation             int32         \n",
      " 63  mois_autorisation              int32         \n",
      "dtypes: bool(4), datetime64[ns](5), float64(4), int32(2), int64(39), object(7), string(3)\n",
      "memory usage: 793.4+ MB\n",
      "  REG_CODE  REG_LIBELLE DEP_CODE DEP_LIBELLE  COMM TYPE_DAU        NUM_DAU  \\\n",
      "0       82  Rhône-Alpes        1         Ain  1001       PC  00100113V0003   \n",
      "1       82  Rhône-Alpes        1         Ain  1001       PC  00100113V0004   \n",
      "2       82  Rhône-Alpes        1         Ain  1001       PC  00100113V0006   \n",
      "3       82  Rhône-Alpes        1         Ain  1001       PC  00100113V0007   \n",
      "4       82  Rhône-Alpes        1         Ain  1001       PC  00100113V0008   \n",
      "\n",
      "   ETAT_DAU DATE_REELLE_AUTORISATION DATE_REELLE_DOC  ...  \\\n",
      "0         5               2013-09-20      2013-11-26  ...   \n",
      "1         6               2013-09-30      2013-12-06  ...   \n",
      "2         6               2013-09-20      2013-11-26  ...   \n",
      "3         6               2013-11-16      2014-01-24  ...   \n",
      "4         6               2013-12-06      2014-03-12  ...   \n",
      "\n",
      "  SURF_BUR_TRANSFORMEE SURF_COM_TRANSFORMEE SURF_ART_TRANSFORMEE  \\\n",
      "0                    0                    0                    0   \n",
      "1                    0                    0                    0   \n",
      "2                    0                    0                    0   \n",
      "3                    0                    0                    0   \n",
      "4                    0                    0                    0   \n",
      "\n",
      "  SURF_IND_TRANSFORMEE SURF_AGR_TRANSFORMEE  delai_ouverture_chantier  \\\n",
      "0                    0                    0                      67.0   \n",
      "1                    0                    0                      67.0   \n",
      "2                    0                    0                      67.0   \n",
      "3                    0                    0                      69.0   \n",
      "4                    0                    0                      96.0   \n",
      "\n",
      "  duree_travaux  duree_obtiention_autorisation  annee_autorisation  \\\n",
      "0           NaN                           92.0                2013   \n",
      "1         245.0                           61.0                2013   \n",
      "2         213.0                           61.0                2013   \n",
      "3          75.0                           31.0                2013   \n",
      "4         247.0                           30.0                2013   \n",
      "\n",
      "   mois_autorisation  \n",
      "0                  9  \n",
      "1                  9  \n",
      "2                  9  \n",
      "3                 11  \n",
      "4                 12  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "  CODGEO                   LIBGEO  DENS                         LIBDENS  \\\n",
      "0  01001  L'Abergement-Clémenciat     6        Rural à habitat dispersé   \n",
      "1  01002    L'Abergement-de-Varey     6        Rural à habitat dispersé   \n",
      "2  01004        Ambérieu-en-Bugey     2  Centres urbains intermédiaires   \n",
      "3  01005      Ambérieux-en-Dombes     5                   Bourgs ruraux   \n",
      "4  01006                  Ambléon     6        Rural à habitat dispersé   \n",
      "\n",
      "   PMUN17   P1     P2   P3     P4     P5      P6     P7  \n",
      "0     776  0.0   0.00  0.0   0.00   0.00   78.60  21.40  \n",
      "1     248  0.0   0.00  0.0   0.00   0.00   88.08  11.92  \n",
      "2   14035  0.0  70.85  0.0  24.85   0.00    3.54   0.75  \n",
      "3    1689  0.0   0.00  0.0   0.00  83.08    9.42   7.50  \n",
      "4     111  0.0   0.00  0.0   0.00   0.00  100.00   0.00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34970 entries, 0 to 34969\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CODGEO   34970 non-null  object \n",
      " 1   LIBGEO   34970 non-null  object \n",
      " 2   DENS     34970 non-null  int64  \n",
      " 3   LIBDENS  34970 non-null  object \n",
      " 4   PMUN17   34970 non-null  int64  \n",
      " 5   P1       34970 non-null  float64\n",
      " 6   P2       34970 non-null  float64\n",
      " 7   P3       34970 non-null  float64\n",
      " 8   P4       34970 non-null  float64\n",
      " 9   P5       34970 non-null  float64\n",
      " 10  P6       34970 non-null  float64\n",
      " 11  P7       34970 non-null  float64\n",
      "dtypes: float64(7), int64(2), object(3)\n",
      "memory usage: 3.2+ MB\n",
      "['CODGEO', 'LIBGEO', 'DENS', 'LIBDENS', 'PMUN17', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7']\n",
      "Pourcentage sans densité: 0.76%\n",
      "['CODGEO', 'P22_POP', 'P22_POP0014', 'P22_POP1529', 'P22_POP3044', 'P22_POP4559', 'P22_POP6074', 'P22_POP7589', 'P22_POP90P', 'P22_POPH', 'P22_H0014', 'P22_H1529', 'P22_H3044', 'P22_H4559', 'P22_H6074', 'P22_H7589', 'P22_H90P', 'P22_H0019', 'P22_H2064', 'P22_H65P', 'P22_POPF', 'P22_F0014', 'P22_F1529', 'P22_F3044', 'P22_F4559', 'P22_F6074', 'P22_F7589', 'P22_F90P', 'P22_F0019', 'P22_F2064', 'P22_F65P', 'P22_POP01P', 'P22_POP01P_IRAN1', 'P22_POP01P_IRAN2', 'P22_POP01P_IRAN3', 'P22_POP01P_IRAN4', 'P22_POP01P_IRAN5', 'P22_POP01P_IRAN6', 'P22_POP01P_IRAN7', 'P22_POP0114_IRAN2P', 'P22_POP0114_IRAN2', 'P22_POP0114_IRAN3P', 'P22_POP1524_IRAN2P', 'P22_POP1524_IRAN2', 'P22_POP1524_IRAN3P', 'P22_POP2554_IRAN2P', 'P22_POP2554_IRAN2', 'P22_POP2554_IRAN3P', 'P22_POP55P_IRAN2P', 'P22_POP55P_IRAN2', 'P22_POP55P_IRAN3P', 'C22_POP15P', 'C22_POP15P_STAT_GSEC11_21', 'C22_POP15P_STAT_GSEC12_22', 'C22_POP15P_STAT_GSEC13_23', 'C22_POP15P_STAT_GSEC14_24', 'C22_POP15P_STAT_GSEC15_25', 'C22_POP15P_STAT_GSEC16_26', 'C22_POP15P_STAT_GSEC32', 'C22_POP15P_STAT_GSEC40', 'C22_H15P', 'C22_H15P_STAT_GSEC11_21', 'C22_H15P_STAT_GSEC12_22', 'C22_H15P_STAT_GSEC13_23', 'C22_H15P_STAT_GSEC14_24', 'C22_H15P_STAT_GSEC15_25', 'C22_H15P_STAT_GSEC16_26', 'C22_F15P', 'C22_F15P_STAT_GSEC11_21', 'C22_F15P_STAT_GSEC12_22', 'C22_F15P_STAT_GSEC13_23', 'C22_F15P_STAT_GSEC14_24', 'C22_F15P_STAT_GSEC15_25', 'C22_F15P_STAT_GSEC16_26', 'C22_POP1524', 'C22_POP1524_STAT_GSEC11_21', 'C22_POP1524_STAT_GSEC12_22', 'C22_POP1524_STAT_GSEC13_23', 'C22_POP1524_STAT_GSEC14_24', 'C22_POP1524_STAT_GSEC15_25', 'C22_POP1524_STAT_GSEC16_26', 'C22_POP2554', 'C22_POP2554_STAT_GSEC11_21', 'C22_POP2554_STAT_GSEC12_22', 'C22_POP2554_STAT_GSEC13_23', 'C22_POP2554_STAT_GSEC14_24', 'C22_POP2554_STAT_GSEC15_25', 'C22_POP2554_STAT_GSEC16_26', 'C22_POP55P', 'C22_POP55P_STAT_GSEC11_21', 'C22_POP55P_STAT_GSEC12_22', 'C22_POP55P_STAT_GSEC13_23', 'C22_POP55P_STAT_GSEC14_24', 'C22_POP55P_STAT_GSEC15_25', 'C22_POP55P_STAT_GSEC16_26', 'P16_POP', 'P16_POP0014', 'P16_POP1529', 'P16_POP3044', 'P16_POP4559', 'P16_POP6074', 'P16_POP7589', 'P16_POP90P', 'P16_POPH', 'P16_H0014', 'P16_H1529', 'P16_H3044', 'P16_H4559', 'P16_H6074', 'P16_H7589', 'P16_H90P', 'P16_H0019', 'P16_H2064', 'P16_H65P', 'P16_POPF', 'P16_F0014', 'P16_F1529', 'P16_F3044', 'P16_F4559', 'P16_F6074', 'P16_F7589', 'P16_F90P', 'P16_F0019', 'P16_F2064', 'P16_F65P', 'P16_POP01P', 'P16_POP01P_IRAN1', 'P16_POP01P_IRAN2', 'P16_POP01P_IRAN3', 'P16_POP01P_IRAN4', 'P16_POP01P_IRAN5', 'P16_POP01P_IRAN6', 'P16_POP01P_IRAN7', 'P16_POP0114_IRAN2P', 'P16_POP0114_IRAN2', 'P16_POP0114_IRAN3P', 'P16_POP1524_IRAN2P', 'P16_POP1524_IRAN2', 'P16_POP1524_IRAN3P', 'P16_POP2554_IRAN2P', 'P16_POP2554_IRAN2', 'P16_POP2554_IRAN3P', 'P16_POP55P_IRAN2P', 'P16_POP55P_IRAN2', 'P16_POP55P_IRAN3P', 'C16_POP15P', 'C16_POP15P_CS1', 'C16_POP15P_CS2', 'C16_POP15P_CS3', 'C16_POP15P_CS4', 'C16_POP15P_CS5', 'C16_POP15P_CS6', 'C16_H15P', 'C16_H15P_CS1', 'C16_H15P_CS2', 'C16_H15P_CS3', 'C16_H15P_CS4', 'C16_H15P_CS5', 'C16_H15P_CS6', 'C16_F15P', 'C16_F15P_CS1', 'C16_F15P_CS2', 'C16_F15P_CS3', 'C16_F15P_CS4', 'C16_F15P_CS5', 'C16_F15P_CS6', 'C16_POP1524', 'C16_POP1524_CS1', 'C16_POP1524_CS2', 'C16_POP1524_CS3', 'C16_POP1524_CS4', 'C16_POP1524_CS5', 'C16_POP1524_CS6', 'C16_POP2554', 'C16_POP2554_CS1', 'C16_POP2554_CS2', 'C16_POP2554_CS3', 'C16_POP2554_CS4', 'C16_POP2554_CS5', 'C16_POP2554_CS6', 'C16_POP55P', 'C16_POP55P_CS1', 'C16_POP55P_CS2', 'C16_POP55P_CS3', 'C16_POP55P_CS4', 'C16_POP55P_CS5', 'C16_POP55P_CS6', 'P11_POP', 'P11_POP0014', 'P11_POP1529', 'P11_POP3044', 'P11_POP4559', 'P11_POP6074', 'P11_POP7589', 'P11_POP90P', 'P11_POPH', 'P11_H0014', 'P11_H1529', 'P11_H3044', 'P11_H4559', 'P11_H6074', 'P11_H7589', 'P11_H90P', 'P11_H0019', 'P11_H2064', 'P11_H65P', 'P11_POPF', 'P11_F0014', 'P11_F1529', 'P11_F3044', 'P11_F4559', 'P11_F6074', 'P11_F7589', 'P11_F90P', 'P11_F0019', 'P11_F2064', 'P11_F65P', 'P11_POP01P', 'P11_POP01P_IRAN1', 'P11_POP01P_IRAN2', 'P11_POP01P_IRAN3', 'P11_POP01P_IRAN4', 'P11_POP01P_IRAN5', 'P11_POP01P_IRAN6', 'P11_POP01P_IRAN7', 'P11_POP0114_IRAN2P', 'P11_POP0114_IRAN2', 'P11_POP0114_IRAN3P', 'P11_POP1524_IRAN2P', 'P11_POP1524_IRAN2', 'P11_POP1524_IRAN3P', 'P11_POP2554_IRAN2P', 'P11_POP2554_IRAN2', 'P11_POP2554_IRAN3P', 'P11_POP55P_IRAN2P', 'P11_POP55P_IRAN2', 'P11_POP55P_IRAN3P', 'C11_POP15P', 'C11_POP15P_CS1', 'C11_POP15P_CS2', 'C11_POP15P_CS3', 'C11_POP15P_CS4', 'C11_POP15P_CS5', 'C11_POP15P_CS6', 'C11_H15P', 'C11_H15P_CS1', 'C11_H15P_CS2', 'C11_H15P_CS3', 'C11_H15P_CS4', 'C11_H15P_CS5', 'C11_H15P_CS6', 'C11_F15P', 'C11_F15P_CS1', 'C11_F15P_CS2', 'C11_F15P_CS3', 'C11_F15P_CS4', 'C11_F15P_CS5', 'C11_F15P_CS6', 'C11_POP1524', 'C11_POP1524_CS1', 'C11_POP1524_CS2', 'C11_POP1524_CS3', 'C11_POP1524_CS4', 'C11_POP1524_CS5', 'C11_POP1524_CS6', 'C11_POP2554', 'C11_POP2554_CS1', 'C11_POP2554_CS2', 'C11_POP2554_CS3', 'C11_POP2554_CS4', 'C11_POP2554_CS5', 'C11_POP2554_CS6', 'C11_POP55P', 'C11_POP55P_CS1', 'C11_POP55P_CS2', 'C11_POP55P_CS3', 'C11_POP55P_CS4', 'C11_POP55P_CS5', 'C11_POP55P_CS6', 'C22_MEN', 'C22_MENPSEUL', 'C22_MENHSEUL', 'C22_MENFSEUL', 'C22_MENSFAM', 'C22_MENFAM', 'C22_MENCOUPSENF', 'C22_MENCOUPAENF', 'C22_MENFAMMONO', 'C22_PMEN', 'C22_PMEN_MENPSEUL', 'C22_PMEN_MENHSEUL', 'C22_PMEN_MENFSEUL', 'C22_PMEN_MENSFAM', 'C22_PMEN_MENFAM', 'C22_PMEN_MENCOUPSENF', 'C22_PMEN_MENCOUPAENF', 'C22_PMEN_MENFAMMONO', 'P22_POP15P', 'P22_POP1519', 'P22_POP2024', 'P22_POP2539', 'P22_POP4054', 'P22_POP5564', 'P22_POP6579', 'P22_POP80P', 'P22_POPMEN1519', 'P22_POPMEN2024', 'P22_POPMEN2539', 'P22_POPMEN4054', 'P22_POPMEN5564', 'P22_POPMEN6579', 'P22_POPMEN80P', 'P22_POP1519_PSEUL', 'P22_POP2024_PSEUL', 'P22_POP2539_PSEUL', 'P22_POP4054_PSEUL', 'P22_POP5564_PSEUL', 'P22_POP6579_PSEUL', 'P22_POP80P_PSEUL', 'P22_POP1519_COUPLE', 'P22_POP2024_COUPLE', 'P22_POP2539_COUPLE', 'P22_POP4054_COUPLE', 'P22_POP5564_COUPLE', 'P22_POP6579_COUPLE', 'P22_POP80P_COUPLE', 'P22_POP15P_MARIEE', 'P22_POP15P_PACSEE', 'P22_POP15P_CONCUB_UNION_LIBRE', 'P22_POP15P_VEUFS', 'P22_POP15P_DIVORCEE', 'P22_POP15P_CELIBATAIRE', 'C22_MEN_STAT_GSEC11_21', 'C22_MEN_STAT_GSEC12_22', 'C22_MEN_STAT_GSEC13_23', 'C22_MEN_STAT_GSEC14_24', 'C22_MEN_STAT_GSEC15_25', 'C22_MEN_STAT_GSEC16_26', 'C22_MEN_STAT_GSEC32', 'C22_MEN_STAT_GSEC40', 'C22_PMEN_STAT_GSEC11_21', 'C22_PMEN_STAT_GSEC12_22', 'C22_PMEN_STAT_GSEC13_23', 'C22_PMEN_STAT_GSEC14_24', 'C22_PMEN_STAT_GSEC15_25', 'C22_PMEN_STAT_GSEC16_26', 'C22_PMEN_STAT_GSEC32', 'C22_PMEN_STAT_GSEC40', 'C22_FAM', 'C22_COUPAENF', 'C22_FAMMONO', 'C22_HMONO', 'C22_FMONO', 'C22_COUPSENF', 'C22_NE24F0', 'C22_NE24F1', 'C22_NE24F2', 'C22_NE24F3', 'C22_NE24F4P', 'C22_MEN-FAM', 'C22_MEN1FCOUPSENF', 'C22_MEN1FCOUPUNIQENFCOUP', 'C22_MEN1FCOUPENF1ADUL', 'C22_MEN1FMONOH', 'C22_MEN1FMONOF', 'C22_PMENFAM', 'C22_PMEN1FCOUPSENF', 'C22_PMEN1FCOUPUNIQENFCOUP', 'C22_PMEN1FCOUPENF1ADUL', 'C22_PMEN1FMONOH', 'C22_PMEN1FMONOF', 'C22_FAMTRAD', 'C22_FAMRECOMP', 'C16_MEN', 'C16_MENPSEUL', 'C16_MENHSEUL', 'C16_MENFSEUL', 'C16_MENSFAM', 'C16_MENFAM', 'C16_MENCOUPSENF', 'C16_MENCOUPAENF', 'C16_MENFAMMONO', 'C16_PMEN', 'C16_PMEN_MENPSEUL', 'C16_PMEN_MENHSEUL', 'C16_PMEN_MENFSEUL', 'C16_PMEN_MENSFAM', 'C16_PMEN_MENFAM', 'C16_PMEN_MENCOUPSENF', 'C16_PMEN_MENCOUPAENF', 'C16_PMEN_MENFAMMONO', 'P16_POP15P', 'P16_POP1519', 'P16_POP2024', 'P16_POP2539', 'P16_POP4054', 'P16_POP5564', 'P16_POP6579', 'P16_POP80P', 'P16_POPMEN1519', 'P16_POPMEN2024', 'P16_POPMEN2539', 'P16_POPMEN4054', 'P16_POPMEN5564', 'P16_POPMEN6579', 'P16_POPMEN80P', 'P16_POP1519_PSEUL', 'P16_POP2024_PSEUL', 'P16_POP2539_PSEUL', 'P16_POP4054_PSEUL', 'P16_POP5564_PSEUL', 'P16_POP6579_PSEUL', 'P16_POP80P_PSEUL', 'P16_POP1519_COUPLE', 'P16_POP2024_COUPLE', 'P16_POP2539_COUPLE', 'P16_POP4054_COUPLE', 'P16_POP5564_COUPLE', 'P16_POP6579_COUPLE', 'P16_POP80P_COUPLE', 'P16_POP15P_MARIEE', 'P16_POP15P_NONMARIEE', 'C16_MEN_CS1', 'C16_MEN_CS2', 'C16_MEN_CS3', 'C16_MEN_CS4', 'C16_MEN_CS5', 'C16_MEN_CS6', 'C16_PMEN_CS1', 'C16_PMEN_CS2', 'C16_PMEN_CS3', 'C16_PMEN_CS4', 'C16_PMEN_CS5', 'C16_PMEN_CS6', 'C16_FAM', 'C16_COUPAENF', 'C16_FAMMONO', 'C16_HMONO', 'C16_FMONO', 'C16_COUPSENF', 'C16_NE24F0', 'C16_NE24F1', 'C16_NE24F2', 'C16_NE24F3', 'C16_NE24F4P', 'C11_MEN', 'C11_MENPSEUL', 'C11_MENHSEUL', 'C11_MENFSEUL', 'C11_MENSFAM', 'C11_MENFAM', 'C11_MENCOUPSENF', 'C11_MENCOUPAENF', 'C11_MENFAMMONO', 'C11_PMEN', 'C11_PMEN_MENPSEUL', 'C11_PMEN_MENHSEUL', 'C11_PMEN_MENFSEUL', 'C11_PMEN_MENSFAM', 'C11_PMEN_MENFAM', 'C11_PMEN_MENCOUPSENF', 'C11_PMEN_MENCOUPAENF', 'C11_PMEN_MENFAMMONO', 'P11_POP15P', 'P11_POP1519', 'P11_POP2024', 'P11_POP2539', 'P11_POP4054', 'P11_POP5564', 'P11_POP6579', 'P11_POP80P', 'P11_POPMEN1519', 'P11_POPMEN2024', 'P11_POPMEN2539', 'P11_POPMEN4054', 'P11_POPMEN5564', 'P11_POPMEN6579', 'P11_POPMEN80P', 'P11_POP1519_PSEUL', 'P11_POP2024_PSEUL', 'P11_POP2539_PSEUL', 'P11_POP4054_PSEUL', 'P11_POP5564_PSEUL', 'P11_POP6579_PSEUL', 'P11_POP80P_PSEUL', 'P11_POP1519_COUPLE', 'P11_POP2024_COUPLE', 'P11_POP2539_COUPLE', 'P11_POP4054_COUPLE', 'P11_POP5564_COUPLE', 'P11_POP6579_COUPLE', 'P11_POP80P_COUPLE', 'P11_POP15P_MARIE', 'P11_POP15P_CELIB', 'P11_POP15P_VEUF', 'P11_POP15P_DIVOR', 'C11_MEN_CS1', 'C11_MEN_CS2', 'C11_MEN_CS3', 'C11_MEN_CS4', 'C11_MEN_CS5', 'C11_MEN_CS6', 'C11_PMEN_CS1', 'C11_PMEN_CS2', 'C11_PMEN_CS3', 'C11_PMEN_CS4', 'C11_PMEN_CS5', 'C11_PMEN_CS6', 'C11_FAM', 'C11_COUPAENF', 'C11_FAMMONO', 'C11_HMONO', 'C11_FMONO', 'C11_COUPSENF', 'C11_NE24F0', 'C11_NE24F1', 'C11_NE24F2', 'C11_NE24F3', 'C11_NE24F4P', 'P22_LOG', 'P22_RP', 'P22_RSECOCC', 'P22_LOGVAC', 'P22_MAISON', 'P22_APPART', 'P22_RP_1P', 'P22_RP_2P', 'P22_RP_3P', 'P22_RP_4P', 'P22_RP_5PP', 'P22_NBPI_RP', 'P22_RPMAISON', 'P22_NBPI_RPMAISON', 'P22_RPAPPART', 'P22_NBPI_RPAPPART', 'C22_RP_NORME', 'C22_RP_SOUSOCC_MOD', 'C22_RP_SOUSOCC_ACC', 'C22_RP_SOUSOCC_TACC', 'C22_RP_SUROCC_MOD', 'C22_RP_SUROCC_ACC', 'P22_RP_ACHTOT', 'P22_RP_ACH1919', 'P22_RP_ACH1945', 'P22_RP_ACH1970', 'P22_RP_ACH1990', 'P22_RP_ACH2005', 'P22_RP_ACH2019', 'P22_RPMAISON_ACH1919', 'P22_RPMAISON_ACH1945', 'P22_RPMAISON_ACH1970', 'P22_RPMAISON_ACH1990', 'P22_RPMAISON_ACH2005', 'P22_RPMAISON_ACH2019', 'P22_RPAPPART_ACH1919', 'P22_RPAPPART_ACH1945', 'P22_RPAPPART_ACH1970', 'P22_RPAPPART_ACH1990', 'P22_RPAPPART_ACH2005', 'P22_RPAPPART_ACH2019', 'P22_MEN', 'P22_MEN_ANEM0002', 'P22_MEN_ANEM0204', 'P22_MEN_ANEM0509', 'P22_MEN_ANEM10P', 'P22_MEN_ANEM1019', 'P22_MEN_ANEM2029', 'P22_MEN_ANEM30P', 'P22_PMEN', 'P22_PMEN_ANEM0002', 'P22_PMEN_ANEM0204', 'P22_PMEN_ANEM0509', 'P22_PMEN_ANEM10P', 'P22_NBPI_RP_ANEM0002', 'P22_NBPI_RP_ANEM0204', 'P22_NBPI_RP_ANEM0509', 'P22_NBPI_RP_ANEM10P', 'P22_RP_PROP', 'P22_RP_LOC', 'P22_RP_LOCHLMV', 'P22_RP_GRAT', 'P22_NPER_RP', 'P22_NPER_RP_PROP', 'P22_NPER_RP_LOC', 'P22_NPER_RP_LOCHLMV', 'P22_NPER_RP_GRAT', 'P22_ANEM_RP', 'P22_ANEM_RP_PROP', 'P22_ANEM_RP_LOC', 'P22_ANEM_RP_LOCHLMV', 'P22_ANEM_RP_GRAT', 'P22_RP_CGAZV', 'P22_RP_CFIOUL', 'P22_RP_CELEC', 'P22_RP_CGAZB', 'P22_RP_CAUT', 'P22_RP_ELEC', 'P22_RP_EAUCH', 'P22_RP_BDWC', 'P22_RP_CHOS', 'P22_RP_CLIM', 'P22_RP_TTEGOU', 'P22_RP_GARL', 'P22_RP_VOIT1P', 'P22_RP_VOIT1', 'P22_RP_VOIT2P', 'P22_RP_HABFOR', 'P22_RP_CASE', 'P22_RP_MIBOIS', 'P22_RP_MIDUR', 'P16_LOG', 'P16_RP', 'P16_RSECOCC', 'P16_LOGVAC', 'P16_MAISON', 'P16_APPART', 'C16_RP_NORME', 'C16_RP_SOUSOCC_MOD', 'C16_RP_SOUSOCC_ACC', 'C16_RP_SOUSOCC_TACC', 'C16_RP_SUROCC_MOD', 'C16_RP_SUROCC_ACC', 'P16_RP_1P', 'P16_RP_2P', 'P16_RP_3P', 'P16_RP_4P', 'P16_RP_5PP', 'P16_NBPI_RP', 'P16_RPMAISON', 'P16_NBPI_RPMAISON', 'P16_RPAPPART', 'P16_NBPI_RPAPPART', 'P16_RP_ACHTOT', 'P16_RP_ACH19', 'P16_RP_ACH45', 'P16_RP_ACH70', 'P16_RP_ACH90', 'P16_RP_ACH05', 'P16_RP_ACH13', 'P16_RPMAISON_ACH19', 'P16_RPMAISON_ACH45', 'P16_RPMAISON_ACH70', 'P16_RPMAISON_ACH90', 'P16_RPMAISON_ACH05', 'P16_RPMAISON_ACH13', 'P16_RPAPPART_ACH19', 'P16_RPAPPART_ACH45', 'P16_RPAPPART_ACH70', 'P16_RPAPPART_ACH90', 'P16_RPAPPART_ACH05', 'P16_RPAPPART_ACH13', 'P16_MEN', 'P16_MEN_ANEM0002', 'P16_MEN_ANEM0204', 'P16_MEN_ANEM0509', 'P16_MEN_ANEM10P', 'P16_MEN_ANEM1019', 'P16_MEN_ANEM2029', 'P16_MEN_ANEM30P', 'P16_PMEN', 'P16_PMEN_ANEM0002', 'P16_PMEN_ANEM0204', 'P16_PMEN_ANEM0509', 'P16_PMEN_ANEM10P', 'P16_NBPI_RP_ANEM0002', 'P16_NBPI_RP_ANEM0204', 'P16_NBPI_RP_ANEM0509', 'P16_NBPI_RP_ANEM10P', 'P16_RP_PROP', 'P16_RP_LOC', 'P16_RP_LOCHLMV', 'P16_RP_GRAT', 'P16_NPER_RP', 'P16_NPER_RP_PROP', 'P16_NPER_RP_LOC', 'P16_NPER_RP_LOCHLMV', 'P16_NPER_RP_GRAT', 'P16_ANEM_RP', 'P16_ANEM_RP_PROP', 'P16_ANEM_RP_LOC', 'P16_ANEM_RP_LOCHLMV', 'P16_ANEM_RP_GRAT', 'P16_RP_CGAZV', 'P16_RP_CFIOUL', 'P16_RP_CELEC', 'P16_RP_CGAZB', 'P16_RP_CAUT', 'P16_RP_ELEC', 'P16_RP_EAUCH', 'P16_RP_BDWC', 'P16_RP_CHOS', 'P16_RP_CLIM', 'P16_RP_TTEGOU', 'P16_RP_GARL', 'P16_RP_VOIT1P', 'P16_RP_VOIT1', 'P16_RP_VOIT2P', 'P16_RP_HABFOR', 'P16_RP_CASE', 'P16_RP_MIBOIS', 'P16_RP_MIDUR', 'P11_LOG', 'P11_RP', 'P11_RSECOCC', 'P11_LOGVAC', 'P11_MAISON', 'P11_APPART', 'P11_RP_1P', 'P11_RP_2P', 'P11_RP_3P', 'P11_RP_4P', 'P11_RP_5PP', 'P11_NBPI_RP', 'P11_RPMAISON', 'P11_NBPI_RPMAISON', 'P11_RPAPPART', 'P11_NBPI_RPAPPART', 'C11_RP_NORME', 'C11_RP_SOUSOCC_MOD', 'C11_RP_SOUSOCC_ACC', 'C11_RP_SOUSOCC_TACC', 'C11_RP_SUROCC_MOD', 'C11_RP_SUROCC_ACC', 'P11_MEN', 'P11_MEN_ANEM0002', 'P11_MEN_ANEM0204', 'P11_MEN_ANEM0509', 'P11_MEN_ANEM10P', 'P11_MEN_ANEM1019', 'P11_MEN_ANEM2029', 'P11_MEN_ANEM30P', 'P11_PMEN', 'P11_PMEN_ANEM0002', 'P11_PMEN_ANEM0204', 'P11_PMEN_ANEM0509', 'P11_PMEN_ANEM10P', 'P11_NBPI_RP_ANEM0002', 'P11_NBPI_RP_ANEM0204', 'P11_NBPI_RP_ANEM0509', 'P11_NBPI_RP_ANEM10P', 'P11_RP_PROP', 'P11_RP_LOC', 'P11_RP_LOCHLMV', 'P11_RP_GRAT', 'P11_NPER_RP', 'P11_NPER_RP_PROP', 'P11_NPER_RP_LOC', 'P11_NPER_RP_LOCHLMV', 'P11_NPER_RP_GRAT', 'P11_ANEM_RP', 'P11_ANEM_RP_PROP', 'P11_ANEM_RP_LOC', 'P11_ANEM_RP_LOCHLMV', 'P11_ANEM_RP_GRAT', 'P11_RP_CGAZV', 'P11_RP_CFIOUL', 'P11_RP_CELEC', 'P11_RP_CGAZB', 'P11_RP_CAUT', 'P11_RP_ELEC', 'P11_RP_EAUCH', 'P11_RP_BDWC', 'P11_RP_CHOS', 'P11_RP_CLIM', 'P11_RP_TTEGOU', 'P11_RP_GARL', 'P11_RP_VOIT1P', 'P11_RP_VOIT1', 'P11_RP_VOIT2P', 'P11_RP_HABFOR', 'P11_RP_CASE', 'P11_RP_MIBOIS', 'P11_RP_MIDUR', 'P11_RP_ACHT1', 'P11_RP_ACHT2', 'P11_RP_ACHT3', 'P11_RP_ACHTT', 'P11_RPMAISON_ACHT1', 'P11_RPMAISON_ACHT2', 'P11_RPMAISON_ACHT3', 'P11_RPAPPART_ACHT1', 'P11_RPAPPART_ACHT2', 'P11_RPAPPART_ACHT3', 'P22_POP0205', 'P22_POP0610', 'P22_POP1114', 'P22_POP1517', 'P22_POP1824', 'P22_POP2529', 'P22_POP30P', 'P22_SCOL0205', 'P22_SCOL0610', 'P22_SCOL1114', 'P22_SCOL1517', 'P22_SCOL1824', 'P22_SCOL2529', 'P22_SCOL30P', 'P22_H0205', 'P22_H0610', 'P22_H1114', 'P22_H1517', 'P22_H1824', 'P22_H2529', 'P22_H30P', 'P22_HSCOL0205', 'P22_HSCOL0610', 'P22_HSCOL1114', 'P22_HSCOL1517', 'P22_HSCOL1824', 'P22_HSCOL2529', 'P22_HSCOL30P', 'P22_F0205', 'P22_F0610', 'P22_F1114', 'P22_F1517', 'P22_F1824', 'P22_F2529', 'P22_F30P', 'P22_FSCOL0205', 'P22_FSCOL0610', 'P22_FSCOL1114', 'P22_FSCOL1517', 'P22_FSCOL1824', 'P22_FSCOL2529', 'P22_FSCOL30P', 'P22_NSCOL15P', 'P22_NSCOL15P_DIPLMIN', 'P22_NSCOL15P_BEPC', 'P22_NSCOL15P_CAPBEP', 'P22_NSCOL15P_BAC', 'P22_NSCOL15P_SUP2', 'P22_NSCOL15P_SUP34', 'P22_NSCOL15P_SUP5', 'P22_HNSCOL15P', 'P22_HNSCOL15P_DIPLMIN', 'P22_HNSCOL15P_BEPC', 'P22_HNSCOL15P_CAPBEP', 'P22_HNSCOL15P_BAC', 'P22_HNSCOL15P_SUP2', 'P22_HNSCOL15P_SUP34', 'P22_HNSCOL15P_SUP5', 'P22_FNSCOL15P', 'P22_FNSCOL15P_DIPLMIN', 'P22_FNSCOL15P_BEPC', 'P22_FNSCOL15P_CAPBEP', 'P22_FNSCOL15P_BAC', 'P22_FNSCOL15P_SUP2', 'P22_FNSCOL15P_SUP34', 'P22_FNSCOL15P_SUP5', 'P16_POP0205', 'P16_POP0610', 'P16_POP1114', 'P16_POP1517', 'P16_POP1824', 'P16_POP2529', 'P16_POP30P', 'P16_SCOL0205', 'P16_SCOL0610', 'P16_SCOL1114', 'P16_SCOL1517', 'P16_SCOL1824', 'P16_SCOL2529', 'P16_SCOL30P', 'P16_H0205', 'P16_H0610', 'P16_H1114', 'P16_H1517', 'P16_H1824', 'P16_H2529', 'P16_H30P', 'P16_HSCOL0205', 'P16_HSCOL0610', 'P16_HSCOL1114', 'P16_HSCOL1517', 'P16_HSCOL1824', 'P16_HSCOL2529', 'P16_HSCOL30P', 'P16_F0205', 'P16_F0610', 'P16_F1114', 'P16_F1517', 'P16_F1824', 'P16_F2529', 'P16_F30P', 'P16_FSCOL0205', 'P16_FSCOL0610', 'P16_FSCOL1114', 'P16_FSCOL1517', 'P16_FSCOL1824', 'P16_FSCOL2529', 'P16_FSCOL30P', 'P16_NSCOL15P', 'P16_NSCOL15P_DIPLMIN', 'P16_NSCOL15P_CAPBEP', 'P16_NSCOL15P_BAC', 'P16_NSCOL15P_SUP', 'P16_HNSCOL15P', 'P16_HNSCOL15P_DIPLMIN', 'P16_HNSCOL15P_CAPBEP', 'P16_HNSCOL15P_BAC', 'P16_HNSCOL15P_SUP', 'P16_FNSCOL15P', 'P16_FNSCOL15P_DIPLMIN', 'P16_FNSCOL15P_CAPBEP', 'P16_FNSCOL15P_BAC', 'P16_FNSCOL15P_SUP', 'P11_POP0205', 'P11_POP0610', 'P11_POP1114', 'P11_POP1517', 'P11_POP1824', 'P11_POP2529', 'P11_POP30P', 'P11_SCOL0205', 'P11_SCOL0610', 'P11_SCOL1114', 'P11_SCOL1517', 'P11_SCOL1824', 'P11_SCOL2529', 'P11_SCOL30P', 'P11_H0205', 'P11_H0610', 'P11_H1114', 'P11_H1517', 'P11_H1824', 'P11_H2529', 'P11_H30P', 'P11_HSCOL0205', 'P11_HSCOL0610', 'P11_HSCOL1114', 'P11_HSCOL1517', 'P11_HSCOL1824', 'P11_HSCOL2529', 'P11_HSCOL30P', 'P11_F0205', 'P11_F0610', 'P11_F1114', 'P11_F1517', 'P11_F1824', 'P11_F2529', 'P11_F30P', 'P11_FSCOL0205', 'P11_FSCOL0610', 'P11_FSCOL1114', 'P11_FSCOL1517', 'P11_FSCOL1824', 'P11_FSCOL2529', 'P11_FSCOL30P', 'P11_NSCOL15P', 'P11_NSCOL15P_DIPL0', 'P11_NSCOL15P_CEP', 'P11_NSCOL15P_BEPC', 'P11_NSCOL15P_CAPBEP', 'P11_NSCOL15P_BAC', 'P11_NSCOL15P_BACP2', 'P11_NSCOL15P_SUP', 'P11_HNSCOL15P', 'P11_HNSCOL15P_DIPL0', 'P11_HNSCOL15P_CEP', 'P11_HNSCOL15P_BEPC', 'P11_HNSCOL15P_CAPBEP', 'P11_HNSCOL15P_BAC', 'P11_HNSCOL15P_BACP2', 'P11_HNSCOL15P_SUP', 'P11_FNSCOL15P', 'P11_FNSCOL15P_DIPL0', 'P11_FNSCOL15P_CEP', 'P11_FNSCOL15P_BEPC', 'P11_FNSCOL15P_CAPBEP', 'P11_FNSCOL15P_BAC', 'P11_FNSCOL15P_BACP2', 'P11_FNSCOL15P_SUP', 'P22_POP1564', 'P22_POP1524', 'P22_POP2554', 'P22_H1564', 'P22_H1524', 'P22_H2554', 'P22_H5564', 'P22_F1564', 'P22_F1524', 'P22_F2554', 'P22_F5564', 'P22_ACT1564', 'P22_ACT1524', 'P22_ACT2554', 'P22_ACT5564', 'P22_HACT1564', 'P22_HACT1524', 'P22_HACT2554', 'P22_HACT5564', 'P22_FACT1564', 'P22_FACT1524', 'P22_FACT2554', 'P22_FACT5564', 'P22_ACTOCC1564', 'P22_ACTOCC1524', 'P22_ACTOCC2554', 'P22_ACTOCC5564', 'P22_HACTOCC1564', 'P22_HACTOCC1524', 'P22_HACTOCC2554', 'P22_HACTOCC5564', 'P22_FACTOCC1564', 'P22_FACTOCC1524', 'P22_FACTOCC2554', 'P22_FACTOCC5564', 'P22_CHOM1564', 'P22_CHOM1524', 'P22_CHOM2554', 'P22_CHOM5564', 'P22_CHOM_DIPLMIN', 'P22_CHOM_BEPC', 'P22_CHOM_CAPBEP', 'P22_CHOM_BAC', 'P22_CHOM_SUP2', 'P22_CHOM_SUP34', 'P22_CHOM_SUP5', 'P22_ACT_DIPLMIN', 'P22_ACT_BEPC', 'P22_ACT_CAPBEP', 'P22_ACT_BAC', 'P22_ACT_SUP2', 'P22_ACT_SUP34', 'P22_ACT_SUP5', 'P22_INACT1564', 'P22_ETUD1564', 'P22_RETR1564', 'P22_AINACT1564', 'C22_ACT1564', 'C22_ACT1564_STAT_GSEC11_21', 'C22_ACT1564_STAT_GSEC12_22', 'C22_ACT1564_STAT_GSEC13_23', 'C22_ACT1564_STAT_GSEC14_24', 'C22_ACT1564_STAT_GSEC15_25', 'C22_ACT1564_STAT_GSEC16_26', 'C22_ACTOCC1564', 'C22_ACTOCC1564_STAT_GSEC11', 'C22_ACTOCC1564_STAT_GSEC12', 'C22_ACTOCC1564_STAT_GSEC13', 'C22_ACTOCC1564_STAT_GSEC14', 'C22_ACTOCC1564_STAT_GSEC15', 'C22_ACTOCC1564_STAT_GSEC16', 'P22_EMPLT', 'P22_ACTOCC', 'P22_ACT15P', 'P22_EMPLT_SAL', 'P22_EMPLT_FSAL', 'P22_EMPLT_SALTP', 'P22_EMPLT_NSAL', 'P22_EMPLT_FNSAL', 'P22_EMPLT_NSALTP', 'C22_EMPLT', 'C22_EMPLT_GS1', 'C22_EMPLT_GS2', 'C22_EMPLT_GS3', 'C22_EMPLT_GS4', 'C22_EMPLT_GS5', 'C22_EMPLT_GS6', 'C22_EMPLT_AGRI', 'C22_EMPLT_INDUS', 'C22_EMPLT_CONST', 'C22_EMPLT_CTS', 'C22_EMPLT_APESAS', 'C22_EMPLT_F', 'C22_AGRILT_F', 'C22_INDUSLT_F', 'C22_CONSTLT_F', 'C22_CTSLT_F', 'C22_APESASLT_F', 'C22_EMPLT_SAL', 'C22_AGRILT_SAL', 'C22_INDUSLT_SAL', 'C22_CONSTLT_SAL', 'C22_CTSLT_SAL', 'C22_APESASLT_SAL', 'C22_AGRILT_FSAL', 'C22_INDUSLT_FSAL', 'C22_CONSTLT_FSAL', 'C22_CTSLT_FSAL', 'C22_APESASLT_FSAL', 'C22_AGRILT_NSAL', 'C22_INDUSLT_NSAL', 'C22_CONSTLT_NSAL', 'C22_CTSLT_NSAL', 'C22_APESASLT_NSAL', 'C22_AGRILT_FNSAL', 'C22_INDUSLT_FNSAL', 'C22_CONSTLT_FNSAL', 'C22_CTSLT_FNSAL', 'C22_APESASLT_FNSAL', 'P22_HCHOM1564', 'P22_HCHOM1524', 'P22_HCHOM2554', 'P22_HCHOM5564', 'P22_FCHOM1564', 'P22_FCHOM1524', 'P22_FCHOM2554', 'P22_FCHOM5564', 'P16_POP1564', 'P16_POP1524', 'P16_POP2554', 'P16_H1564', 'P16_H1524', 'P16_H2554', 'P16_H5564', 'P16_F1564', 'P16_F1524', 'P16_F2554', 'P16_F5564', 'P16_ACT1564', 'P16_ACT1524', 'P16_ACT2554', 'P16_ACT5564', 'P16_HACT1564', 'P16_HACT1524', 'P16_HACT2554', 'P16_HACT5564', 'P16_FACT1564', 'P16_FACT1524', 'P16_FACT2554', 'P16_FACT5564', 'P16_ACTOCC1564', 'P16_ACTOCC1524', 'P16_ACTOCC2554', 'P16_ACTOCC5564', 'P16_HACTOCC1564', 'P16_HACTOCC1524', 'P16_HACTOCC2554', 'P16_HACTOCC5564', 'P16_FACTOCC1564', 'P16_FACTOCC1524', 'P16_FACTOCC2554', 'P16_FACTOCC5564', 'P16_CHOM1564', 'P16_HCHOM1564', 'P16_HCHOM1524', 'P16_HCHOM2554', 'P16_HCHOM5564', 'P16_FCHOM1564', 'P16_FCHOM1524', 'P16_FCHOM2554', 'P16_FCHOM5564', 'P16_INACT1564', 'P16_ETUD1564', 'P16_RETR1564', 'P16_AINACT1564', 'C16_ACT1564', 'C16_ACT1564_CS1', 'C16_ACT1564_CS2', 'C16_ACT1564_CS3', 'C16_ACT1564_CS4', 'C16_ACT1564_CS5', 'C16_ACT1564_CS6', 'C16_ACTOCC1564', 'C16_ACTOCC1564_CS1', 'C16_ACTOCC1564_CS2', 'C16_ACTOCC1564_CS3', 'C16_ACTOCC1564_CS4', 'C16_ACTOCC1564_CS5', 'C16_ACTOCC1564_CS6', 'P16_EMPLT', 'P16_ACTOCC', 'P16_ACT15P', 'P16_EMPLT_SAL', 'P16_EMPLT_FSAL', 'P16_EMPLT_SALTP', 'P16_EMPLT_NSAL', 'P16_EMPLT_FNSAL', 'P16_EMPLT_NSALTP', 'C16_EMPLT', 'C16_EMPLT_CS1', 'C16_EMPLT_CS2', 'C16_EMPLT_CS3', 'C16_EMPLT_CS4', 'C16_EMPLT_CS5', 'C16_EMPLT_CS6', 'C16_EMPLT_AGRI', 'C16_EMPLT_INDUS', 'C16_EMPLT_CONST', 'C16_EMPLT_CTS', 'C16_EMPLT_APESAS', 'C16_EMPLT_F', 'C16_AGRILT_F', 'C16_INDUSLT_F', 'C16_CONSTLT_F', 'C16_CTSLT_F', 'C16_APESASLT_F', 'C16_EMPLT_SAL', 'C16_AGRILT_SAL', 'C16_INDUSLT_SAL', 'C16_CONSTLT_SAL', 'C16_CTSLT_SAL', 'C16_APESASLT_SAL', 'C16_AGRILT_FSAL', 'C16_INDUSLT_FSAL', 'C16_CONSTLT_FSAL', 'C16_CTSLT_FSAL', 'C16_APESASLT_FSAL', 'C16_AGRILT_NSAL', 'C16_INDUSLT_NSAL', 'C16_CONSTLT_NSAL', 'C16_CTSLT_NSAL', 'C16_APESASLT_NSAL', 'C16_AGRILT_FNSAL', 'C16_INDUSLT_FNSAL', 'C16_CONSTLT_FNSAL', 'C16_CTSLT_FNSAL', 'C16_APESASLT_FNSAL', 'P11_POP1564', 'P11_H1564', 'P11_H1524', 'P11_H2554', 'P11_H5564', 'P11_F1564', 'P11_F1524', 'P11_F2554', 'P11_F5564', 'P11_ACT1564', 'P11_ACT1524', 'P11_ACT2554', 'P11_ACT5564', 'P11_HACT1564', 'P11_HACT1524', 'P11_HACT2554', 'P11_HACT5564', 'P11_FACT1564', 'P11_FACT1524', 'P11_FACT2554', 'P11_FACT5564', 'P11_ACTOCC1564', 'P11_ACTOCC1524', 'P11_ACTOCC2554', 'P11_ACTOCC5564', 'P11_HACTOCC1564', 'P11_HACTOCC1524', 'P11_HACTOCC2554', 'P11_HACTOCC5564', 'P11_FACTOCC1564', 'P11_FACTOCC1524', 'P11_FACTOCC2554', 'P11_FACTOCC5564', 'P11_CHOM1564', 'P11_HCHOM1564', 'P11_HCHOM1524', 'P11_HCHOM2554', 'P11_HCHOM5564', 'P11_FCHOM1564', 'P11_FCHOM1524', 'P11_FCHOM2554', 'P11_FCHOM5564', 'P11_INACT1564', 'P11_ETUD1564', 'P11_RETR1564', 'P11_AINACT1564', 'C11_ACT1564', 'C11_ACT1564_CS1', 'C11_ACT1564_CS2', 'C11_ACT1564_CS3', 'C11_ACT1564_CS4', 'C11_ACT1564_CS5', 'C11_ACT1564_CS6', 'C11_ACTOCC1564', 'C11_ACTOCC1564_CS1', 'C11_ACTOCC1564_CS2', 'C11_ACTOCC1564_CS3', 'C11_ACTOCC1564_CS4', 'C11_ACTOCC1564_CS5', 'C11_ACTOCC1564_CS6', 'P11_EMPLT', 'P11_ACTOCC', 'P11_ACT15P', 'P11_EMPLT_SAL', 'P11_EMPLT_FSAL', 'P11_EMPLT_SALTP', 'P11_EMPLT_NSAL', 'P11_EMPLT_FNSAL', 'P11_EMPLT_NSALTP', 'C11_EMPLT', 'C11_EMPLT_CS1', 'C11_EMPLT_CS2', 'C11_EMPLT_CS3', 'C11_EMPLT_CS4', 'C11_EMPLT_CS5', 'C11_EMPLT_CS6', 'C11_EMPLT_AGRI', 'C11_EMPLT_INDUS', 'C11_EMPLT_CONST', 'C11_EMPLT_CTS', 'C11_EMPLT_APESAS', 'C11_EMPLT_F', 'C11_AGRILT_F', 'C11_INDUSLT_F', 'C11_CONSTLT_F', 'C11_CTSLT_F', 'C11_APESASLT_F', 'C11_EMPLT_SAL', 'C11_AGRILT_SAL', 'C11_INDUSLT_SAL', 'C11_CONSTLT_SAL', 'C11_CTSLT_SAL', 'C11_APESASLT_SAL', 'C11_AGRILT_FSAL', 'C11_INDUSLT_FSAL', 'C11_CONSTLT_FSAL', 'C11_CTSLT_FSAL', 'C11_APESASLT_FSAL', 'C11_AGRILT_NSAL', 'C11_INDUSLT_NSAL', 'C11_CONSTLT_NSAL', 'C11_CTSLT_NSAL', 'C11_APESASLT_NSAL', 'C11_AGRILT_FNSAL', 'C11_INDUSLT_FNSAL', 'C11_CONSTLT_FNSAL', 'C11_CTSLT_FNSAL', 'C11_APESASLT_FNSAL', 'P22_ACTOCC15P', 'P22_SAL15P', 'P22_NSAL15P', 'P22_ACTOCC15P_TP', 'P22_SAL15P_TP', 'P22_HSAL15P_TP', 'P22_FSAL15P_TP', 'P22_NSAL15P_TP', 'P22_HACTOCC15P', 'P22_HSAL15P', 'P22_HSAL15P_CDI', 'P22_HSAL15P_CDD', 'P22_HSAL15P_INTERIM', 'P22_HSAL15P_EMPAID', 'P22_HSAL15P_APPR', 'P22_HNSAL15P', 'P22_HNSAL15P_INDEP', 'P22_HNSAL15P_EMPLOY', 'P22_HNSAL15P_AIDFAM', 'P22_FACTOCC15P', 'P22_FSAL15P', 'P22_FSAL15P_CDI', 'P22_FSAL15P_CDD', 'P22_FSAL15P_INTERIM', 'P22_FSAL15P_EMPAID', 'P22_FSAL15P_APPR', 'P22_FNSAL15P', 'P22_FNSAL15P_INDEP', 'P22_FNSAL15P_EMPLOY', 'P22_FNSAL15P_AIDFAM', 'P22_HSAL1564', 'P22_HSAL1524', 'P22_HSAL2554', 'P22_HSAL5564', 'P22_HSAL1564_TP', 'P22_HSAL1524_TP', 'P22_HSAL2554_TP', 'P22_HSAL5564_TP', 'P22_FSAL1564', 'P22_FSAL1524', 'P22_FSAL2554', 'P22_FSAL5564', 'P22_FSAL1564_TP', 'P22_FSAL1524_TP', 'P22_FSAL2554_TP', 'P22_FSAL5564_TP', 'P22_ACTOCC15P_ILT1', 'P22_ACTOCC15P_ILT2P', 'P22_ACTOCC15P_ILT2', 'P22_ACTOCC15P_ILT3', 'P22_ACTOCC15P_ILT4', 'P22_ACTOCC15P_ILT5', 'P22_ACTOCC15P_PASTRANS', 'P22_ACTOCC15P_MARCHE', 'P22_ACTOCC15P_VELO', 'P22_ACTOCC15P_2ROUESMOT', 'P22_ACTOCC15P_VOITURE', 'P22_ACTOCC15P_COMMUN', 'P16_ACTOCC15P', 'P16_SAL15P', 'P16_NSAL15P', 'P16_ACTOCC15P_TP', 'P16_SAL15P_TP', 'P16_HSAL15P_TP', 'P16_FSAL15P_TP', 'P16_NSAL15P_TP', 'P16_HACTOCC15P', 'P16_HSAL15P', 'P16_HSAL15P_CDI', 'P16_HSAL15P_CDD', 'P16_HSAL15P_INTERIM', 'P16_HSAL15P_EMPAID', 'P16_HSAL15P_APPR', 'P16_HNSAL15P', 'P16_HNSAL15P_INDEP', 'P16_HNSAL15P_EMPLOY', 'P16_HNSAL15P_AIDFAM', 'P16_FACTOCC15P', 'P16_FSAL15P', 'P16_FSAL15P_CDI', 'P16_FSAL15P_CDD', 'P16_FSAL15P_INTERIM', 'P16_FSAL15P_EMPAID', 'P16_FSAL15P_APPR', 'P16_FNSAL15P', 'P16_FNSAL15P_INDEP', 'P16_FNSAL15P_EMPLOY', 'P16_FNSAL15P_AIDFAM', 'P16_HSAL1564', 'P16_HSAL1524', 'P16_HSAL2554', 'P16_HSAL5564', 'P16_HSAL1564_TP', 'P16_HSAL1524_TP', 'P16_HSAL2554_TP', 'P16_HSAL5564_TP', 'P16_FSAL1564', 'P16_FSAL1524', 'P16_FSAL2554', 'P16_FSAL5564', 'P16_FSAL1564_TP', 'P16_FSAL1524_TP', 'P16_FSAL2554_TP', 'P16_FSAL5564_TP', 'P16_ACTOCC15P_ILT1', 'P16_ACTOCC15P_ILT2P', 'P16_ACTOCC15P_ILT2', 'P16_ACTOCC15P_ILT3', 'P16_ACTOCC15P_ILT4', 'P16_ACTOCC15P_ILT5', 'P16_ACTOCC15P_PASTRANS', 'P16_ACTOCC15P_MARCHE', 'P16_ACTOCC15P_2ROUES', 'P16_ACTOCC15P_VOITURE', 'P16_ACTOCC15P_COMMUN', 'P11_ACTOCC15P', 'P11_SAL15P', 'P11_NSAL15P', 'P11_ACTOCC15P_TP', 'P11_SAL15P_TP', 'P11_HSAL15P_TP', 'P11_FSAL15P_TP', 'P11_NSAL15P_TP', 'P11_HACTOCC15P', 'P11_HSAL15P', 'P11_HSAL15P_CDI', 'P11_HSAL15P_CDD', 'P11_HSAL15P_INTERIM', 'P11_HSAL15P_EMPAID', 'P11_HSAL15P_APPR', 'P11_HNSAL15P', 'P11_HNSAL15P_INDEP', 'P11_HNSAL15P_EMPLOY', 'P11_HNSAL15P_AIDFAM', 'P11_FACTOCC15P', 'P11_FSAL15P', 'P11_FSAL15P_CDI', 'P11_FSAL15P_CDD', 'P11_FSAL15P_INTERIM', 'P11_FSAL15P_EMPAID', 'P11_FSAL15P_APPR', 'P11_FNSAL15P', 'P11_FNSAL15P_INDEP', 'P11_FNSAL15P_EMPLOY', 'P11_FNSAL15P_AIDFAM', 'P11_HSAL1564', 'P11_HSAL1524', 'P11_HSAL2554', 'P11_HSAL5564', 'P11_HSAL1564_TP', 'P11_HSAL1524_TP', 'P11_HSAL2554_TP', 'P11_HSAL5564_TP', 'P11_FSAL1564', 'P11_FSAL1524', 'P11_FSAL2554', 'P11_FSAL5564', 'P11_FSAL1564_TP', 'P11_FSAL1524_TP', 'P11_FSAL2554_TP', 'P11_FSAL5564_TP', 'P11_ACTOCC15P_ILT1', 'P11_ACTOCC15P_ILT2P', 'P11_ACTOCC15P_ILT2', 'P11_ACTOCC15P_ILT3', 'P11_ACTOCC15P_ILT4', 'P11_ACTOCC15P_ILT5', 'P11_ACTOCC15P_PASTRANS', 'P11_ACTOCC15P_MARCHE', 'P11_ACTOCC15P_2ROUES', 'P11_ACTOCC15P_VOITURE', 'P11_ACTOCC15P_COMMUN', 'P06_POP', 'D99_POP', 'D90_POP', 'D82_POP', 'D75_POP', 'D68_POP', 'SUPERF', 'NAIS1621', 'NAIS1115', 'NAIS0610', 'NAIS9905', 'NAIS9099', 'NAIS8290', 'NAIS7582', 'NAIS6875', 'DECE1621', 'DECE1115', 'DECE0610', 'DECE9905', 'DECE9099', 'DECE8290', 'DECE7582', 'DECE6875', 'P06_LOG', 'D99_LOG', 'D90_LOG', 'D82_LOG', 'D75_LOG', 'D68_LOG', 'P06_RP', 'D99_RP', 'D90_RP', 'D82_RP', 'D75_RP', 'D68_RP', 'P06_RSECOCC', 'D99_RSECOCC', 'D90_RSECOCC', 'D82_RSECOCC', 'D75_RSECOCC', 'D68_RSECOCC', 'P06_LOGVAC', 'D99_LOGVAC', 'D90_LOGVAC', 'D82_LOGVAC', 'D75_LOGVAC', 'D68_LOGVAC', 'P06_PMEN', 'D99_PMEN', 'D90_NPER_RP', 'D82_NPER_RP', 'D75_NPER_RP', 'D68_NPER_RP', 'NAISD14', 'NAISD15', 'NAISD16', 'NAISD17', 'NAISD18', 'NAISD19', 'NAISD20', 'NAISD21', 'NAISD22', 'NAISD23', 'NAISD24', 'DECESD14', 'DECESD15', 'DECESD16', 'DECESD17', 'DECESD18', 'DECESD19', 'DECESD20', 'DECESD21', 'DECESD22', 'DECESD23', 'DECESD24', 'NBMENFISC21', 'NBPERSMENFISC21', 'MED21', 'PIMP21', 'TP6021', 'TP60AGE121', 'TP60AGE221', 'TP60AGE321', 'TP60AGE421', 'TP60AGE521', 'TP60AGE621', 'TP60TOL121', 'TP60TOL221', 'PACT21', 'PTSA21', 'PCHO21', 'PBEN21', 'PPEN21', 'PPAT21', 'PPSOC21', 'PPFAM21', 'PPMINI21', 'PPLOGT21', 'PIMPOT21', 'D121', 'D921', 'RD21', 'SNEMM_23', 'SNEMM_SEX_F_23', 'SNEMM_SEX_M_23', 'SNEMM_AGE_Y_LT25_23', 'SNEMM_AGE_Y25T39_23', 'SNEMM_AGE_Y40T49_23', 'SNEMM_AGE_Y50T54_23', 'SNEMM_AGE_Y_GE55_23', 'SNEMM_PCS_ESE_1T3_23', 'SNEMM_PCS_ESE_4_23', 'SNEMM_PCS_ESE_5_23', 'SNEMM_PCS_ESE_6_23', 'SNEMM_SEX_F_AGE_Y_LT25_23', 'SNEMM_SEX_F_AGE_Y25T39_23', 'SNEMM_SEX_F_AGE_Y40T49_23', 'SNEMM_SEX_F_AGE_Y50T54_23', 'SNEMM_SEX_F_AGE_Y_GE55_23', 'SNEMM_SEX_M_AGE_Y_LT25_23', 'SNEMM_SEX_M_AGE_Y25T39_23', 'SNEMM_SEX_M_AGE_Y40T49_23', 'SNEMM_SEX_M_AGE_Y50T54_23', 'SNEMM_SEX_M_AGE_Y_GE55_23', 'SNEMM_SEX_F_PCS_ESE_1T3_23', 'SNEMM_SEX_F_PCS_ESE_4_23', 'SNEMM_SEX_F_PCS_ESE_5_23', 'SNEMM_SEX_F_PCS_ESE_6_23', 'SNEMM_SEX_M_PCS_ESE_1T3_23', 'SNEMM_SEX_M_PCS_ESE_4_23', 'SNEMM_SEX_M_PCS_ESE_5_23', 'SNEMM_SEX_M_PCS_ESE_6_23', 'ETTOT23', 'ETAZ23', 'ETBE23', 'ETFZ23', 'ETGU23', 'ETOQ23', 'ETTEF023', 'ETAZ023', 'ETBE023', 'ETFZ023', 'ETGU023', 'ETOQ023', 'ETTEF123', 'ETAZ123', 'ETBE123', 'ETFZ123', 'ETGU123', 'ETOQ123', 'ETTEF1023', 'ETAZ1023', 'ETBE1023', 'ETFZ1023', 'ETGU1023', 'ETOQ1023', 'ETTEF2023', 'ETAZ2023', 'ETBE2023', 'ETFZ2023', 'ETGU2023', 'ETOQ2023', 'ETTEF5023', 'ETAZ5023', 'ETBE5023', 'ETFZ5023', 'ETGU5023', 'ETOQ5023', 'ETPTOT23', 'ETPAZ23', 'ETPBE23', 'ETPFZ23', 'ETPGU23', 'ETPOQ23', 'ETPTEF123', 'ETPAZ123', 'ETPBE123', 'ETPFZ123', 'ETPGU123', 'ETPOQ123', 'ETPTEF1023', 'ETPAZ1023', 'ETPBE1023', 'ETPFZ1023', 'ETPGU1023', 'ETPOQ1023', 'ETPTEF2023', 'ETPAZ2023', 'ETPBE2023', 'ETPFZ2023', 'ETPGU2023', 'ETPOQ2023', 'ETPTEF5023', 'ETPAZ5023', 'ETPBE5023', 'ETPFZ5023', 'ETPGU5023', 'ETPOQ5023', 'ETPTEFCP23', 'ETPAZCP23', 'ETPBECP23', 'ETPFZCP23', 'ETPGUCP23', 'ETPOQCP23', 'ETPRES23', 'ETNPRES23', 'ETPRESPUB23', 'ETNPRESPUB23', 'ETPPRES23', 'ETPNPRES23', 'ETPPRESPUB23', 'ETPNPRESPUB23', 'ETASSMAT23', 'ETAUTRES23', 'ENCTOT24', 'ENCBE24', 'ENCFZ24', 'ENCGI24', 'ENCJZ24', 'ENCKZ24', 'ENCLZ24', 'ENCMN24', 'ENCOQ24', 'ENCRU24', 'ENCTOT23', 'ENCTOT22', 'ENCTOT21', 'ENCTOT20', 'ENCTOT19', 'ENCTOT18', 'ENCTOT17', 'ENCTOT16', 'ENCTOT15', 'ENCTOT14', 'ENCTOT13', 'ENCTOT12', 'ENCITOT24', 'ENCIBE24', 'ENCIFZ24', 'ENCIGI24', 'ENCIJZ24', 'ENCIKZ24', 'ENCILZ24', 'ENCIMN24', 'ENCIOQ24', 'ENCIRU24', 'ENCITOT23', 'ENCITOT22', 'ENCITOT21', 'ENCITOT20', 'ENCITOT19', 'ENCITOT18', 'ENCITOT17', 'ENCITOT16', 'ENCITOT15', 'ENCITOT14', 'ENCITOT13', 'ENCITOT12', 'ETCTOT24', 'ETCBE24', 'ETCFZ24', 'ETCGI24', 'ETCJZ24', 'ETCKZ24', 'ETCLZ24', 'ETCMN24', 'ETCOQ24', 'ETCRU24', 'ETCTOT23', 'ETCBE23', 'ETCFZ23', 'ETCGI23', 'ETCJZ23', 'ETCKZ23', 'ETCLZ23', 'ETCMN23', 'ETCOQ23', 'ETCRU23', 'ETCTOT22', 'ETCBE22', 'ETCFZ22', 'ETCGI22', 'ETCJZ22', 'ETCKZ22', 'ETCLZ22', 'ETCMN22', 'ETCOQ22', 'ETCRU22', 'ETCTOT21', 'ETCBE21', 'ETCFZ21', 'ETCGI21', 'ETCJZ21', 'ETCKZ21', 'ETCLZ21', 'ETCMN21', 'ETCOQ21', 'ETCRU21', 'ETCTOT20', 'ETCBE20', 'ETCFZ20', 'ETCGI20', 'ETCJZ20', 'ETCKZ20', 'ETCLZ20', 'ETCMN20', 'ETCOQ20', 'ETCRU20', 'ETCTOT19', 'ETCBE19', 'ETCFZ19', 'ETCGI19', 'ETCJZ19', 'ETCKZ19', 'ETCLZ19', 'ETCMN19', 'ETCOQ19', 'ETCRU19', 'ETCTOT18', 'ETCBE18', 'ETCFZ18', 'ETCGI18', 'ETCJZ18', 'ETCKZ18', 'ETCLZ18', 'ETCMN18', 'ETCOQ18', 'ETCRU18', 'ETCTOT17', 'ETCBE17', 'ETCFZ17', 'ETCGI17', 'ETCJZ17', 'ETCKZ17', 'ETCLZ17', 'ETCMN17', 'ETCOQ17', 'ETCRU17', 'ETCTOT16', 'ETCBE16', 'ETCFZ16', 'ETCGI16', 'ETCJZ16', 'ETCKZ16', 'ETCLZ16', 'ETCMN16', 'ETCOQ16', 'ETCRU16', 'ETCTOT15', 'ETCBE15', 'ETCFZ15', 'ETCGI15', 'ETCJZ15', 'ETCKZ15', 'ETCLZ15', 'ETCMN15', 'ETCOQ15', 'ETCRU15', 'ETCTOT14', 'ETCBE14', 'ETCFZ14', 'ETCGI14', 'ETCJZ14', 'ETCKZ14', 'ETCLZ14', 'ETCMN14', 'ETCOQ14', 'ETCRU14', 'ETCTOT13', 'ETCBE13', 'ETCFZ13', 'ETCGI13', 'ETCJZ13', 'ETCKZ13', 'ETCLZ13', 'ETCMN13', 'ETCOQ13', 'ETCRU13', 'ETCTOT12', 'ETCBE12', 'ETCFZ12', 'ETCGI12', 'ETCJZ12', 'ETCKZ12', 'ETCLZ12', 'ETCMN12', 'ETCOQ12', 'ETCRU12', 'ENNTOT23', 'ENNBE23', 'ENNFZ23', 'ENNGI23', 'ENNJZ23', 'ENNKZ23', 'ENNLZ23', 'ENNMN23', 'ENNOQ23', 'ENNRU23', 'ETNTOT23', 'ETNBE23', 'ETNFZ23', 'ETNGI23', 'ETNJZ23', 'ETNKZ23', 'ETNLZ23', 'ETNMN23', 'ETNOQ23', 'ETNRU23', 'HT25', 'HT025', 'HT125', 'HT225', 'HT325', 'HT425', 'HT525', 'HTCH25', 'HTCH025', 'HTCH125', 'HTCH225', 'HTCH325', 'HTCH425', 'HTCH525', 'CPG25', 'CPG025', 'CPG125', 'CPG225', 'CPG325', 'CPG425', 'CPG525', 'CPGE25', 'CPGE025', 'CPGE125', 'CPGE225', 'CPGE325', 'CPGE425', 'CPGE525', 'CPGEL25', 'CPGEL025', 'CPGEL125', 'CPGEL225', 'CPGEL325', 'CPGEL425', 'CPGEL525', 'CPGEO25', 'CPGEO025', 'CPGEO125', 'CPGEO225', 'CPGEO325', 'CPGEO425', 'CPGEO525', 'VV25', 'VVUH25', 'VVLIT25', 'RT25', 'RTUH25', 'RTLIT25', 'AJCS25', 'AJCSUH25', 'AJCSLIT25', 'ELECTEURSLP2024', 'ELECTEURSLP2020', 'ELECTEURSLP2021', 'ELECTEURSLP2022', 'BPE_2024_A501', 'BPE_2024_B104', 'BPE_2024_B105', 'BPE_2024_B201', 'BPE_2024_B202', 'BPE_2024_B207', 'BPE_2024_B316', 'BPE_2024_B326', 'BPE_2024_C107', 'BPE_2024_C108', 'BPE_2024_C109', 'BPE_2024_C201', 'BPE_2024_C301', 'BPE_2024_C302', 'BPE_2024_C303', 'BPE_2024_C304', 'BPE_2024_C305', 'BPE_2024_D250', 'BPE_2024_D265', 'BPE_2024_D277', 'BPE_2024_D279', 'BPE_2024_D281', 'BPE_2024_D307', 'BPE_2024_F307']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasss\\AppData\\Local\\Temp\\ipykernel_16544\\4108641768.py:68: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dossier_complet = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1747808 entries, 0 to 1747807\n",
      "Data columns (total 82 columns):\n",
      " #   Column                         Dtype         \n",
      "---  ------                         -----         \n",
      " 0   REG_CODE                       string        \n",
      " 1   REG_LIBELLE                    object        \n",
      " 2   DEP_CODE                       string        \n",
      " 3   DEP_LIBELLE                    object        \n",
      " 4   COMM                           object        \n",
      " 5   TYPE_DAU                       object        \n",
      " 6   NUM_DAU                        object        \n",
      " 7   ETAT_DAU                       int64         \n",
      " 8   DATE_REELLE_AUTORISATION       datetime64[ns]\n",
      " 9   DATE_REELLE_DOC                datetime64[ns]\n",
      " 10  DATE_REELLE_DAACT              datetime64[ns]\n",
      " 11  DPC_PREM                       datetime64[ns]\n",
      " 12  DPC_AUT                        datetime64[ns]\n",
      " 13  DPC_DOC                        object        \n",
      " 14  DPC_DERN                       object        \n",
      " 15  CAT_DEM                        int64         \n",
      " 16  APE_DEM                        object        \n",
      " 17  CJ_DEM                         float64       \n",
      " 18  REC_ARCHI                      bool          \n",
      " 19  SUPERFICIE_TERRAIN             int64         \n",
      " 20  ZONE_OP                        int64         \n",
      " 21  NATURE_PROJET_DECLAREE         int64         \n",
      " 22  I_EXTENSION                    bool          \n",
      " 23  I_SURELEVATION                 bool          \n",
      " 24  I_NIVSUPP                      bool          \n",
      " 25  NB_NIV_MAX                     int64         \n",
      " 26  UTILISATION                    int64         \n",
      " 27  RES_PRINCIP_OU_SECOND          int64         \n",
      " 28  TYP_ANNEXE                     int64         \n",
      " 29  RESIDENCE                      int64         \n",
      " 30  NB_LGT_TOT_CREES               int64         \n",
      " 31  NB_LGT_IND_CREES               int64         \n",
      " 32  NB_LGT_COL_CREES               int64         \n",
      " 33  NB_LGT_DEMOLIS                 int64         \n",
      " 34  NB_LGT_1P                      int64         \n",
      " 35  NB_LGT_2P                      int64         \n",
      " 36  NB_LGT_3P                      int64         \n",
      " 37  NB_LGT_4P                      int64         \n",
      " 38  NB_LGT_5P                      int64         \n",
      " 39  NB_LGT_6P_PLUS                 int64         \n",
      " 40  NB_LGT_PRET_LOC_SOCIAL         int64         \n",
      " 41  NB_LGT_ACC_SOC_HORS_PTZ        int64         \n",
      " 42  NB_LGT_PTZ                     int64         \n",
      " 43  SURF_HAB_AVANT                 int64         \n",
      " 44  SURF_HAB_CREEE                 int64         \n",
      " 45  SURF_HAB_ISSUE_TRANSFO         int64         \n",
      " 46  SURF_HAB_DEMOLIE               int64         \n",
      " 47  SURF_HAB_TRANSFORMEE           int64         \n",
      " 48  SURF_LOC_AVANT                 int64         \n",
      " 49  SURF_LOC_CREEE                 int64         \n",
      " 50  SURF_LOC_ISSUE_TRANSFO         int64         \n",
      " 51  SURF_LOC_DEMOLIE               int64         \n",
      " 52  SURF_LOC_TRANSFORMEE           int64         \n",
      " 53  SURF_HEB_TRANSFORMEE           int64         \n",
      " 54  SURF_BUR_TRANSFORMEE           int64         \n",
      " 55  SURF_COM_TRANSFORMEE           int64         \n",
      " 56  SURF_ART_TRANSFORMEE           int64         \n",
      " 57  SURF_IND_TRANSFORMEE           int64         \n",
      " 58  SURF_AGR_TRANSFORMEE           int64         \n",
      " 59  delai_ouverture_chantier       float64       \n",
      " 60  duree_travaux                  float64       \n",
      " 61  duree_obtiention_autorisation  float64       \n",
      " 62  annee_autorisation             int32         \n",
      " 63  mois_autorisation              int32         \n",
      " 64  CODGEO_x                       object        \n",
      " 65  DENS                           float64       \n",
      " 66  PMUN17                         float64       \n",
      " 67  CODGEO_y                       object        \n",
      " 68  P16_LOG                        float64       \n",
      " 69  P16_RP                         float64       \n",
      " 70  P16_RSECOCC                    float64       \n",
      " 71  P16_LOGVAC                     float64       \n",
      " 72  P16_MAISON                     float64       \n",
      " 73  P16_APPART                     float64       \n",
      " 74  P16_NSCOL15P                   float64       \n",
      " 75  P16_CHOM1564                   float64       \n",
      " 76  P16_ACTOCC15P                  float64       \n",
      " 77  DECE1621                       float64       \n",
      " 78  MED21                          float64       \n",
      " 79  PIMP21                         object        \n",
      " 80  TP6021                         object        \n",
      " 81  PPEN21                         object        \n",
      "dtypes: bool(4), datetime64[ns](5), float64(17), int32(2), int64(39), object(13), string(2)\n",
      "memory usage: 1.0+ GB\n",
      "         variable                                        description  share_na\n",
      "0           MED21            Médiane des revenus fiscaux (€) en 2021  0.028820\n",
      "1          PPEN21        Part des pensions dans le revenu fiscal (%)  0.024170\n",
      "2          TP6021  Taux de pauvreté à 60% du niveau de vie médian...  0.024170\n",
      "3          PIMP21               Part des ménages fiscaux imposés (%)  0.024170\n",
      "4      P16_APPART                                Appartements (2016)  0.012049\n",
      "5         P16_LOG                   Nombre total de logements (2022)  0.012049\n",
      "6      P16_LOGVAC                           Logements vacants (2016)  0.012049\n",
      "7     P16_RSECOCC  Résidences secondaires et logements occasionne...  0.012049\n",
      "8          P16_RP            Nombre de résidences principales (2016)  0.012049\n",
      "9    P16_CHOM1564                          Chômeurs 15–64 ans (2016)  0.012049\n",
      "10   P16_NSCOL15P           Population 15+ ans non scolarisée (2016)  0.012049\n",
      "11  P16_ACTOCC15P                      Actifs occupés 15+ ans (2016)  0.012049\n",
      "12     P16_MAISON                       Maisons individuelles (2016)  0.012049\n",
      "13       DECE1621         Nombre de décès cumulés entre 2016 et 2021  0.012003\n",
      "14         PMUN17                         Population municipale 2017  0.007625\n",
      "15           DENS  Niveau de densité communale (1 = très dense, 7...  0.007625\n",
      "16           COMM           Code INSEE de la commune (autorisations)  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# 1. Chargement des autorisations nettoyées\n",
    "# Chemin a déjà été défini plus haut\n",
    "\n",
    "df = pd.read_parquet(chemin_data / \"autorisations.parquet\")\n",
    "\n",
    "df.info()\n",
    "print(df.head())\n",
    "\n",
    "# 2. Chargement de données externes\n",
    "# 2.1. Grille de densité à 7 niveaux\n",
    "grille_densite = pd.read_excel(\n",
    "    chemin_grilles,\n",
    "    skiprows=4\n",
    ")\n",
    "print(grille_densite.head())\n",
    "grille_densite.info()\n",
    "print(grille_densite.columns.tolist())\n",
    "\n",
    "cols_grille = [\n",
    "    \"CODGEO\",\n",
    "    \"DENS\",# De 1 à 7\n",
    "    \"PMUN17\" #Pop° municipale 2017\n",
    "]\n",
    "grille_reduite = grille_densite[cols_grille]\n",
    "\n",
    "# On corrige les formats\n",
    "df[\"COMM\"] = df[\"COMM\"].astype(str).str.zfill(5)\n",
    "grille_densite[\"CODGEO\"] = grille_densite[\"CODGEO\"].astype(str).str.zfill(5)\n",
    "\n",
    "# On fait un left-join (i.e. on enrichit les autorisations)\n",
    "df = df.merge(\n",
    "    grille_reduite,\n",
    "    how=\"left\",\n",
    "    left_on=\"COMM\",\n",
    "    right_on=\"CODGEO\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "# On evalue les manquants\n",
    "missing_rate = df[\"DENS\"].isna().mean()\n",
    "print(f\"Pourcentage sans densité: {missing_rate:.2%}\")\n",
    "\n",
    "# 2.2. Dossier complet INSEE\n",
    "all_cols = pd.read_csv(chemin_dossier, sep=\";\", skiprows=0, nrows=1).columns.tolist()\n",
    "print(all_cols)\n",
    "\n",
    "cols_dossier_complet = [\n",
    "    \"CODGEO\", #code Insee\n",
    "    \"TP6021\",# taux pauvreté 60% en 2021 (retirée car trop de NA - secret statistique)\n",
    "    \"MED21\", #Médiane des revenus fiscaux en 2021\"\n",
    "    \"PIMP21\", #part de ménages fiscaux imposés (retirée car trop de NA - secret statistique)\n",
    "    \"PPEN21\", #Part des pensions dans le revenu fiscal (proxy pour concentration personnes âgées) (retirée car trop de NA - secret statistique)\n",
    "    \"DECE1621\", #nbr de deces entre 2016 et 2021\n",
    "    \"P16_LOG\", #nbr de logements dans la commune en 2022\n",
    "    \"P16_RP\", #RP en 2016\n",
    "    \"P16_RSECOCC\", #nbr de résidences secondaires et logements occasionnels en 2016\n",
    "    \"P16_LOGVAC\", #nbr de logements vacants en 2016 \n",
    "    \"P16_MAISON\", # Maisons individuelles en 2016\n",
    "    \"P16_APPART\",  #Appartements en 2016 \n",
    "    \"P16_NSCOL15P\", #Pop 15 ans ou plus non scolarisée en 2016\n",
    "    \"P16_ACTOCC15P\", #Actifs occupés 15 ans ou plus en 2016\n",
    "    \"P16_CHOM1564\", #Chômeurs 15-64 ans en 2016 (princ);\n",
    "]\n",
    "\n",
    "dossier_complet = pd.read_csv(\n",
    "    chemin_dossier,\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8\",\n",
    "    skiprows=0,\n",
    "    usecols=cols_dossier_complet\n",
    ")\n",
    "\n",
    "dossier_complet[\"CODGEO\"] = dossier_complet[\"CODGEO\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Certaines colonnes devraient être numériques mais ne le sont pas à cause des infos de secret statistique\n",
    "cols_num = [\"MED21\"] #on ne met plus le taux de pauvreté, car trop de NA\n",
    "\n",
    "for col in cols_num:\n",
    "    dossier_complet[col] = (\n",
    "        dossier_complet[col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .replace(INSEE_secret_stat, None)\n",
    "        .str.replace(\"\\xa0\", \"\", regex=False)  # espace insécable\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# On fait un left-join (i.e. on enrichit les autorisations)\n",
    "df = df.merge(\n",
    "    dossier_complet,\n",
    "    how=\"left\",\n",
    "    left_on=\"COMM\",\n",
    "    right_on=\"CODGEO\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "df.info()\n",
    "df.to_parquet(\n",
    "    chemin_data / \"autorisations_enrichies.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# 3. Compte des valeurs manquantes pour l'ensemble des variables du dossier complet ajoutées\n",
    "variable_dict = {\n",
    "    # Identifiers\n",
    "    \"COMM\": \"Code INSEE de la commune (autorisations)\",\n",
    "    \"CODGEO\": \"Code INSEE de la commune (sources externes)\",\n",
    "\n",
    "    # Grille densité\n",
    "    \"DENS\": \"Niveau de densité communale (1 = très dense, 7 = très peu dense)\",\n",
    "    \"PMUN17\": \"Population municipale 2017\",\n",
    "\n",
    "    # Socio-éco (INSEE – dossier complet)\n",
    "    \"TP6021\": \"Taux de pauvreté à 60% du niveau de vie médian (2021)\",\n",
    "    \"MED21\": \"Médiane des revenus fiscaux (€) en 2021\",\n",
    "    \"PIMP21\": \"Part des ménages fiscaux imposés (%)\",\n",
    "    \"PPEN21\": \"Part des pensions dans le revenu fiscal (%)\",\n",
    "    \"DECE1621\": \"Nombre de décès cumulés entre 2016 et 2021\",\n",
    "    \"P16_LOG\": \"Nombre total de logements (2022)\",\n",
    "    \"P16_RP\": \"Nombre de résidences principales (2016)\",\n",
    "    \"P16_RSECOCC\": \"Résidences secondaires et logements occasionnels (2016)\",\n",
    "    \"P16_LOGVAC\": \"Logements vacants (2016)\",\n",
    "    \"P16_MAISON\": \"Maisons individuelles (2016)\",\n",
    "    \"P16_APPART\": \"Appartements (2016)\",\n",
    "    \"P16_NSCOL15P\": \"Population 15+ ans non scolarisée (2016)\",\n",
    "    \"P16_ACTOCC15P\": \"Actifs occupés 15+ ans (2016)\",\n",
    "    \"P16_CHOM1564\": \"Chômeurs 15–64 ans (2016)\"\n",
    "}\n",
    "\n",
    "vars_added = [v for v in variable_dict.keys() if v in df.columns]\n",
    "\n",
    "summary_table = (\n",
    "    pd.DataFrame({\n",
    "        \"variable\": vars_added,\n",
    "        \"description\": [variable_dict[v] for v in vars_added],\n",
    "        \"share_na\": [df[v].isna().mean() for v in vars_added]\n",
    "    })\n",
    "    .sort_values(\"share_na\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(summary_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfcb3a",
   "metadata": {},
   "source": [
    "# 4. Prepocessing\n",
    "Le pré-traitement vise à construire un échantillon homogène, économiquement interprétable et compatible avec nos estimations, en premier lieu un lasso. À partir des autorisations enrichies, les observations sans délai d’ouverture de chantier sont exclues, tout comme les départements d’outre-mer afin de limiter l’hétérogénéité. L’analyse est restreinte à la période 2015–2019, afin de réduire les temps de calcul, et ne pas devoir prendre en compte le bousculement majeur qu'a été le premier confinement. Les annulations sont retirées et les délais sont élagués en fixant un plafond à deux ans (730 jours), entre le 95e et 99e percentile, afin de réduire l'influence des outliers. \n",
    "\n",
    "Enfin, les variables numériques sont standardisées afin de rendre les coefficients comparables sous pénalisation ℓ₁, tandis que les variables qualitatives sont encodées en indicatrices via un one-hot encoding. S'inspirant des codes des TD, l’ensemble du pré-traitement est intégré dans un pipeline sklearn. Nous conservons à la fin de ce prétraitement 530 000 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc4a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seuil 95e percentile : 501.0 jours\n",
      "Seuil 99e percentile : 1027.0 jours\n",
      "[INFO] Observations après filtrage NA : 529,403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# LIBRAIRIES de sklearn\n",
    "# Pour le preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# A) Préparation des données pour le LASSO\n",
    "\n",
    "# Variables supplémentaires à retirer du jeu de données final\n",
    "vars_inutiles_delai_ouverture = [\n",
    "    \"COMM\",\n",
    "    \"REG_CODE\",\n",
    "    \"REG_LIBELLE\",\n",
    "    \"DEP_LIBELLE\",\n",
    "    \"NUM_DAU\",\n",
    "    \"APE_DEM\",\n",
    "    \"CJ_DEM\",\n",
    "    \"duree_obtiention_autorisation\",\n",
    "    \"DATE_REELLE_AUTORISATION\",\n",
    "    \"DATE_REELLE_DAACT\",\n",
    "    \"DATE_REELLE_DOC\",\n",
    "    \"DPC_AUT\",\n",
    "    \"DPC_PREM\",\n",
    "    \"DPC_DOC\",\n",
    "    \"DPC_DERN\", \n",
    "    \"duree_travaux\"]\n",
    "\n",
    "# Variables à traiter en One-Hot Encoding\n",
    "vars_categ = [\n",
    "    \"DEP_CODE\", \n",
    "    \"TYPE_DAU\", \n",
    "    \"ETAT_DAU\", \n",
    "    \"CAT_DEM\",\n",
    "    \"ZONE_OP\",\n",
    "    \"NATURE_PROJET_DECLAREE\",\n",
    "    \"UTILISATION\",\n",
    "    \"RES_PRINCIP_OU_SECOND\",\n",
    "    \"TYP_ANNEXE\",\n",
    "    \"RESIDENCE\" ] #on ne met pas la grille de densité pour ne pas perdre la nature hiérarchique de la variable (1 à 7)\n",
    "\n",
    "df = pd.read_parquet(chemin_data / \"autorisations_enrichies.parquet\")\n",
    "\n",
    "# Filtrage des régions et des années\n",
    "regions_outremer = [\n",
    "    \"Guadeloupe\", \"Martinique\", \"Guyane\",\n",
    "    \"La Réunion\", \"Mayotte\"\n",
    "]\n",
    "\n",
    "df_filtre_delai_ouverture = df.dropna(subset=[\"delai_ouverture_chantier\"])\n",
    "df_filtre_delai_ouverture = df_filtre_delai_ouverture[\n",
    "    ~df_filtre_delai_ouverture[\"REG_LIBELLE\"].isin(regions_outremer)\n",
    "]\n",
    "\n",
    "# On ne conserve que 2015-2019, et on retire les outliers (annulations, et délais dépassent 2 ans, entre 95 et 99e percentile)\n",
    "p95 = df_filtre_delai_ouverture[\"delai_ouverture_chantier\"].quantile(0.95)\n",
    "p99 = df_filtre_delai_ouverture[\"delai_ouverture_chantier\"].quantile(0.99)\n",
    "print(f\"Seuil 95e percentile : {p95:.1f} jours\")\n",
    "print(f\"Seuil 99e percentile : {p99:.1f} jours\")\n",
    "\n",
    "df_filtre_delai_ouverture = df_filtre_delai_ouverture[(df_filtre_delai_ouverture[\"annee_autorisation\"] >= 2015) & (df_filtre_delai_ouverture[\"annee_autorisation\"] <= 2019)]\n",
    "df_filtre_delai_ouverture = df_filtre_delai_ouverture[df_filtre_delai_ouverture[\"delai_ouverture_chantier\"] <= 730]\n",
    "df_filtre_delai_ouverture = df_filtre_delai_ouverture[df_filtre_delai_ouverture[\"ETAT_DAU\"] != 4] #on retire les annulations\n",
    "\n",
    "# Nettoyage et conversion des types sur l'échantillon\n",
    "df_filtre_delai_ouverture = df_filtre_delai_ouverture.drop(columns=vars_inutiles_delai_ouverture, errors=\"ignore\")\n",
    "\n",
    "# Suppression des lignes sans variable cible\n",
    "df_model = df_filtre_delai_ouverture.dropna(subset=[\"delai_ouverture_chantier\"])\n",
    "\n",
    "# On définit X et y\n",
    "y = df_model[\"delai_ouverture_chantier\"]\n",
    "X = df_model.drop(columns=[\"delai_ouverture_chantier\"])\n",
    "\n",
    "# Colonnes numériques\n",
    "num_cols = X.select_dtypes(\n",
    "    include=[\"float\", \"int\", \"bool\"]\n",
    ").columns.tolist()\n",
    "\n",
    "# Colonnes catégorielles\n",
    "cat_cols = X.select_dtypes(\n",
    "    include=[\"string\"]\n",
    ").columns.tolist()\n",
    "\n",
    "# On gère les NAs des variables explicatives\n",
    "cols_utiles = num_cols + cat_cols\n",
    "n_before_na = len(X)\n",
    "\n",
    "# Suppression des lignes avec NA sur les variables explicatives\n",
    "X = X.dropna(subset=cols_utiles)\n",
    "y = y.loc[X.index] \n",
    "\n",
    "n_after_na = len(X)\n",
    "drop_rate = 100 * (1 - n_after_na / n_before_na)\n",
    "\n",
    "print(f\"Observations après filtrage NA : {n_after_na:,}\")\n",
    "\n",
    "# B) Pipeline de pré-traitement et modèle LASSO\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Mise à l'échelle des variables numériques (StandardScaler)\n",
    "        (\"num\", StandardScaler(), num_cols), \n",
    "        # Encodage One-Hot des variables catégorielles\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder='drop' # On jette ce qui reste\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32e43d",
   "metadata": {},
   "source": [
    "# 5. Régression LASSO\n",
    "Notre première estimation repose sur un modèle LASSO. La pénalisation ℓ₁, paramétrée ici par un coefficient de régularisation fixé à (\\alpha = 0{,}1) permet de limiter le sur-apprentissage et d’opérer une sélection automatique des variables en contraignant certains coefficients à zéro. Le modèle est entraîné sur l’échantillon d’apprentissage, puis évalué séparément sur les données de test à l’aide de métriques standards de régression (RMSE, MAE et (R^2)), afin de comparer les performances in-sample et out-of-sample. L’analyse est complétée par l’extraction des coefficients non nuls, commentés dans le rapport.\n",
    "\n",
    "Enfin, une spécification alternative est testée en modélisant le logarithme du délai, dans le but de réduire l’asymétrie de la variable cible (i.e. une queue de distribution épaisse) : celle-ci requiert une adaptation du paramètre alpha. Nous avons utilisé LassoCV, proche de GridSearchCV présenté en TD mais plus rapide pour notre cadre d'analyse, afin de trouver l'alpha optimal, plus petit que celui en niveau afin de ne pas augmenter la pénalisation. Les prédictions obtenues n'améliorent néanmoins pas notre estimation : la variance prédite semble resserée par la transformation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbf8587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train : 114.23\n",
      "RMSE test  : 115.09\n",
      "MAE train  : 79.15\n",
      "MAE test   : 79.49\n",
      "R² train   : 0.116\n",
      "R² test    : 0.113\n",
      "R2 sur le test: 0.11290707203046157\n",
      "Nombre de coefficients non nuls : 91\n",
      "\n",
      "Variables les plus explicatives :\n",
      "                    variable       coef   abs_coef\n",
      "79               DEP_CODE_2A  56.786577  56.786577\n",
      "114               DEP_CODE_6  49.126571  49.126571\n",
      "80               DEP_CODE_2B  39.989087  39.989087\n",
      "130              DEP_CODE_74  37.804645  37.804645\n",
      "151              DEP_CODE_93  35.645912  35.645912\n",
      "152              DEP_CODE_94  34.479096  34.479096\n",
      "150              DEP_CODE_92  32.310171  32.310171\n",
      "140              DEP_CODE_83  31.193930  31.193930\n",
      "134              DEP_CODE_78  29.077502  29.077502\n",
      "149              DEP_CODE_91  27.367677  27.367677\n",
      "142              DEP_CODE_85 -25.088927  25.088927\n",
      "153              DEP_CODE_95  24.320848  24.320848\n",
      "28            SURF_HAB_CREEE  23.604310  23.604310\n",
      "121              DEP_CODE_66 -23.579150  23.579150\n",
      "62               DEP_CODE_13  23.536384  23.536384\n",
      "133              DEP_CODE_77  23.157925  23.157925\n",
      "124              DEP_CODE_69  22.332723  22.332723\n",
      "111              DEP_CODE_57 -21.292378  21.292378\n",
      "129              DEP_CODE_73  21.149824  21.149824\n",
      "90               DEP_CODE_38  20.702845  20.702845\n",
      "128              DEP_CODE_72 -17.260073  17.260073\n",
      "102              DEP_CODE_49 -16.709696  16.709696\n",
      "1                    CAT_DEM  15.766328  15.766328\n",
      "135              DEP_CODE_79 -15.198309  15.198309\n",
      "144              DEP_CODE_87 -14.999173  14.999173\n",
      "123              DEP_CODE_68 -12.594726  12.594726\n",
      "110              DEP_CODE_56  12.105553  12.105553\n",
      "143              DEP_CODE_86 -11.694417  11.694417\n",
      "74               DEP_CODE_25 -10.393486  10.393486\n",
      "43        annee_autorisation   9.494482   9.494482\n",
      "86               DEP_CODE_34  -9.231004   9.231004\n",
      "58                DEP_CODE_1   8.458312   8.458312\n",
      "141              DEP_CODE_84   8.445272   8.445272\n",
      "87               DEP_CODE_35  -7.392012   7.392012\n",
      "119              DEP_CODE_64   6.922702   6.922702\n",
      "104              DEP_CODE_50  -5.511144   5.511144\n",
      "54              P16_CHOM1564   5.511133   5.511133\n",
      "16          NB_LGT_COL_CREES  -5.484296   5.484296\n",
      "45                      DENS  -5.232887   5.232887\n",
      "30          SURF_HAB_DEMOLIE   4.667402   4.667402\n",
      "97               DEP_CODE_44  -4.596155   4.596155\n",
      "108              DEP_CODE_54  -4.189776   4.189776\n",
      "73               DEP_CODE_24   3.869552   3.869552\n",
      "50                P16_LOGVAC  -3.824789   3.824789\n",
      "125               DEP_CODE_7   3.680680   3.680680\n",
      "51                P16_MAISON   3.677666   3.677666\n",
      "22                 NB_LGT_5P  -3.658833   3.658833\n",
      "12                TYP_ANNEXE   3.656175   3.656175\n",
      "18                 NB_LGT_1P  -3.478764   3.478764\n",
      "85               DEP_CODE_33   3.297843   3.297843\n",
      "15          NB_LGT_IND_CREES   3.212183   3.212183\n",
      "44         mois_autorisation   2.970117   2.970117\n",
      "49               P16_RSECOCC   2.816319   2.816319\n",
      "11     RES_PRINCIP_OU_SECOND   2.579023   2.579023\n",
      "21                 NB_LGT_4P  -2.301198   2.301198\n",
      "29    SURF_HAB_ISSUE_TRANSFO   2.276029   2.276029\n",
      "0                   ETAT_DAU  -2.217129   2.217129\n",
      "2                  REC_ARCHI   2.182186   2.182186\n",
      "6                I_EXTENSION   2.143427   2.143427\n",
      "9                 NB_NIV_MAX   2.045573   2.045573\n",
      "89               DEP_CODE_37  -1.932037   1.932037\n",
      "115              DEP_CODE_60   1.817247   1.817247\n",
      "10               UTILISATION  -1.764185   1.764185\n",
      "23            NB_LGT_6P_PLUS  -1.685012   1.685012\n",
      "13                 RESIDENCE  -1.640338   1.640338\n",
      "57                     MED21   1.638657   1.638657\n",
      "24    NB_LGT_PRET_LOC_SOCIAL   1.523489   1.523489\n",
      "7             I_SURELEVATION   1.422536   1.422536\n",
      "42      SURF_AGR_TRANSFORMEE   1.352095   1.352095\n",
      "5     NATURE_PROJET_DECLAREE   1.296478   1.296478\n",
      "20                 NB_LGT_3P   1.272246   1.272246\n",
      "4                    ZONE_OP   1.236721   1.236721\n",
      "19                 NB_LGT_2P  -1.213497   1.213497\n",
      "138              DEP_CODE_81  -1.097759   1.097759\n",
      "3         SUPERFICIE_TERRAIN   0.976436   0.976436\n",
      "56                  DECE1621  -0.975795   0.975795\n",
      "33            SURF_LOC_CREEE  -0.672109   0.672109\n",
      "39      SURF_COM_TRANSFORMEE  -0.598259   0.598259\n",
      "38      SURF_BUR_TRANSFORMEE   0.593654   0.593654\n",
      "118              DEP_CODE_63  -0.560682   0.560682\n",
      "26                NB_LGT_PTZ  -0.465262   0.465262\n",
      "8                  I_NIVSUPP   0.445641   0.445641\n",
      "25   NB_LGT_ACC_SOC_HORS_PTZ   0.430464   0.430464\n",
      "41      SURF_IND_TRANSFORMEE  -0.389158   0.389158\n",
      "27            SURF_HAB_AVANT   0.370309   0.370309\n",
      "32            SURF_LOC_AVANT  -0.283799   0.283799\n",
      "70               DEP_CODE_21  -0.282901   0.282901\n",
      "40      SURF_ART_TRANSFORMEE  -0.260782   0.260782\n",
      "17            NB_LGT_DEMOLIS  -0.247353   0.247353\n",
      "34    SURF_LOC_ISSUE_TRANSFO  -0.209395   0.209395\n",
      "35          SURF_LOC_DEMOLIE  -0.182261   0.182261\n",
      "                   variable       coef   abs_coef\n",
      "79              DEP_CODE_2A  56.786577  56.786577\n",
      "114              DEP_CODE_6  49.126571  49.126571\n",
      "80              DEP_CODE_2B  39.989087  39.989087\n",
      "130             DEP_CODE_74  37.804645  37.804645\n",
      "151             DEP_CODE_93  35.645912  35.645912\n",
      "..                      ...        ...        ...\n",
      "70              DEP_CODE_21  -0.282901   0.282901\n",
      "40     SURF_ART_TRANSFORMEE  -0.260782   0.260782\n",
      "17           NB_LGT_DEMOLIS  -0.247353   0.247353\n",
      "34   SURF_LOC_ISSUE_TRANSFO  -0.209395   0.209395\n",
      "35         SURF_LOC_DEMOLIE  -0.182261   0.182261\n",
      "\n",
      "[91 rows x 3 columns]\n",
      "\n",
      "Variables éliminées par le LASSO :\n",
      "['NB_LGT_TOT_CREES', 'SURF_HAB_TRANSFORMEE', 'SURF_LOC_TRANSFORMEE', 'SURF_HEB_TRANSFORMEE', 'PMUN17', 'P16_LOG', 'P16_RP', 'P16_APPART', 'P16_NSCOL15P', 'P16_ACTOCC15P', 'DEP_CODE_10', 'DEP_CODE_11', 'DEP_CODE_12', 'DEP_CODE_14', 'DEP_CODE_15', 'DEP_CODE_16', 'DEP_CODE_17', 'DEP_CODE_18', 'DEP_CODE_19', 'DEP_CODE_2', 'DEP_CODE_22', 'DEP_CODE_23', 'DEP_CODE_26', 'DEP_CODE_27', 'DEP_CODE_28', 'DEP_CODE_29', 'DEP_CODE_3', 'DEP_CODE_30', 'DEP_CODE_31', 'DEP_CODE_32', 'DEP_CODE_36', 'DEP_CODE_39', 'DEP_CODE_4', 'DEP_CODE_40', 'DEP_CODE_41', 'DEP_CODE_42', 'DEP_CODE_43', 'DEP_CODE_45', 'DEP_CODE_46', 'DEP_CODE_47', 'DEP_CODE_48', 'DEP_CODE_5', 'DEP_CODE_51', 'DEP_CODE_52', 'DEP_CODE_53', 'DEP_CODE_55', 'DEP_CODE_58', 'DEP_CODE_59', 'DEP_CODE_61', 'DEP_CODE_62', 'DEP_CODE_65', 'DEP_CODE_67', 'DEP_CODE_70', 'DEP_CODE_71', 'DEP_CODE_75', 'DEP_CODE_76', 'DEP_CODE_8', 'DEP_CODE_80', 'DEP_CODE_82', 'DEP_CODE_88', 'DEP_CODE_89', 'DEP_CODE_9', 'DEP_CODE_90']\n",
      "\n",
      "[LASSO – log(durée + 1), évalué sur l’échelle originale]\n",
      "RMSE train : 141.99\n",
      "RMSE test  : 180.71\n",
      "MAE train  : 77.03\n",
      "MAE test   : 76.82\n",
      "R² train   : -0.359\n",
      "R² test    : -1.231\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "\n",
    "lasso_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", lasso)\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lasso_pipeline.predict(X_train)\n",
    "y_test_pred = lasso_pipeline.predict(X_test)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"RMSE train : {train_rmse:.2f}\")\n",
    "print(f\"RMSE test  : {test_rmse:.2f}\")\n",
    "print(f\"MAE train  : {train_mae:.2f}\")\n",
    "print(f\"MAE test   : {test_mae:.2f}\")\n",
    "print(f\"R² train   : {train_r2:.3f}\")\n",
    "print(f\"R² test    : {test_r2:.3f}\")\n",
    "\n",
    "print('R2 sur le test: {}'.format(lasso_pipeline.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# Nombre de coefficients non nuls\n",
    "coefs = lasso_pipeline.named_steps[\"model\"].coef_\n",
    "nb_nonzero = np.sum(coefs != 0)\n",
    "print(\"Nombre de coefficients non nuls :\", nb_nonzero)\n",
    "\n",
    "# Liste des coefficients non nuls \n",
    "feature_names = (\n",
    "    list(num_cols) +\n",
    "    list(lasso_pipeline.named_steps[\"preprocess\"]\n",
    "         .named_transformers_[\"cat\"]\n",
    "         .get_feature_names_out(cat_cols))\n",
    ")\n",
    "coef_df = (\n",
    "    pd.DataFrame({\"variable\": feature_names, \"coef\": coefs})\n",
    "      .assign(abs_coef=lambda d: d.coef.abs())\n",
    ")\n",
    "print(\"\\nVariables les plus explicatives :\")\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    print(coef_df.query(\"coef != 0\").sort_values(\"abs_coef\", ascending=False))\n",
    "print(coef_df.query(\"coef != 0\").sort_values(\"abs_coef\", ascending=False))\n",
    "\n",
    "# Variables non explicatives\n",
    "print(\"\\nVariables éliminées par le LASSO :\")\n",
    "print(coef_df.query(\"coef == 0\").variable.tolist())\n",
    "\n",
    "\n",
    "#### Version avec transformation log de y ####\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X, y_log,\n",
    "    test_size=0.2,\n",
    "    random_state=36\n",
    ")\n",
    "\n",
    "# On doit modifier un peu notre pipeline, notamment pour l'hyperparamètre alpha: voir script plus bas\n",
    "lasso_log = Lasso(alpha=0.001, max_iter=10_000)\n",
    "\n",
    "lasso_log_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", lasso_log)\n",
    "])\n",
    "\n",
    "lasso_log_pipeline.fit(X_train2, y_train2)\n",
    "\n",
    "# On calcule les prédictions du log\n",
    "y_train_log_pred = lasso_log_pipeline.predict(X_train2)\n",
    "y_test_log_pred = lasso_log_pipeline.predict(X_test2)\n",
    "\n",
    "# On revient à l'échelle originale pour la comparabilité\n",
    "y_train_pred = np.expm1(y_train_log_pred)\n",
    "y_test_pred = np.expm1(y_test_log_pred)\n",
    "\n",
    "y_train_true = np.expm1(y_train2)\n",
    "y_test_true = np.expm1(y_test2)\n",
    "\n",
    "# On calcule les métriques\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_true, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train_true, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train_true, y_train_pred)\n",
    "test_r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print(\"\\n[LASSO – log(durée + 1), évalué sur l’échelle originale]\")\n",
    "print(f\"RMSE train : {train_rmse:.2f}\")\n",
    "print(f\"RMSE test  : {test_rmse:.2f}\")\n",
    "print(f\"MAE train  : {train_mae:.2f}\")\n",
    "print(f\"MAE test   : {test_mae:.2f}\")\n",
    "print(f\"R² train   : {train_r2:.3f}\")\n",
    "print(f\"R² test    : {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c54ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha optimal : 0.001\n"
     ]
    }
   ],
   "source": [
    "# Choix de l'hyperparamètre alpha \n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_cv = LassoCV(\n",
    "    alphas=np.logspace(-3, 0, 10),\n",
    "    cv=5,\n",
    "    max_iter=10_000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lasso_log_pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", lasso_cv)\n",
    "])\n",
    "\n",
    "lasso_log_pipeline.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"Alpha optimal :\", lasso_cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2e677",
   "metadata": {},
   "source": [
    "# 6. Random forest\n",
    "\n",
    "Nous conservons la même plage d’étude (2015–2019) et cherchons à améliorer le pouvoir prédictif du modèle en recourant à une méthode d’ensemble non paramétrique, la forêt aléatoire. Cela devrait nous permettre de capturer des relations non linéaires et des interactions complexes entre variables explicatives, difficilement prises en compte par les modèles linéaires.\n",
    "\n",
    "Le premier chunk nous permet de choisir les hyperparamètres du modèle à l’aide d’une procédure de recherche aléatoire avec élimination successive (*HalvingRandomSearchCV*). Cette méthode évalue un grand nombre de configurations sur un nombre limité de ressources, puis concentre progressivement l’effort de calcul sur les configurations les plus prometteuses. La ressource considérée ici est le nombre d’arbres de la forêt (*n_estimators*), augmenté itérativement de 50 à 350.\n",
    "\n",
    "La recherche porte sur trois hyperparamètres clés :\n",
    "- la profondeur maximale des arbres (*max_depth*), qui contrôle la complexité du modèle ;\n",
    "- le nombre minimal d’observations par feuille (*min_samples_leaf*), qui joue un rôle de régularisation ;\n",
    "- la proportion de variables considérées à chaque séparation (*max_features*), qui accroît la diversité des arbres.\n",
    "\n",
    "La performance des modèles est évaluée par validation croisée à trois plis, en utilisant le coefficient de détermination \\(R^2\\) comme fonction de score, conformément au cadre de régression étudié. Les hyperparamètres retenus correspondent à la configuration maximisant la performance moyenne en validation croisée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9b254b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 50\n",
      "max_resources_: 350\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 7\n",
      "n_resources: 50\n",
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] END model__max_depth=12, model__max_features=sqrt, model__min_samples_leaf=20, model__n_estimators=50; total time=   8.2s\n",
      "[CV] END model__max_depth=12, model__max_features=sqrt, model__min_samples_leaf=20, model__n_estimators=50; total time=  10.5s\n",
      "[CV] END model__max_depth=12, model__max_features=sqrt, model__min_samples_leaf=20, model__n_estimators=50; total time=   9.3s\n",
      "[CV] END model__max_depth=6, model__max_features=0.5, model__min_samples_leaf=50, model__n_estimators=50; total time=  24.0s\n",
      "[CV] END model__max_depth=6, model__max_features=0.5, model__min_samples_leaf=50, model__n_estimators=50; total time=  23.7s\n",
      "[CV] END model__max_depth=6, model__max_features=0.5, model__min_samples_leaf=50, model__n_estimators=50; total time=  23.5s\n",
      "[CV] END model__max_depth=8, model__max_features=0.3, model__min_samples_leaf=20, model__n_estimators=50; total time=  18.0s\n",
      "[CV] END model__max_depth=8, model__max_features=0.3, model__min_samples_leaf=20, model__n_estimators=50; total time=  18.7s\n",
      "[CV] END model__max_depth=8, model__max_features=0.3, model__min_samples_leaf=20, model__n_estimators=50; total time=  17.8s\n",
      "[CV] END model__max_depth=12, model__max_features=0.5, model__min_samples_leaf=10, model__n_estimators=50; total time=  36.7s\n",
      "[CV] END model__max_depth=12, model__max_features=0.5, model__min_samples_leaf=10, model__n_estimators=50; total time=  36.1s\n",
      "[CV] END model__max_depth=12, model__max_features=0.5, model__min_samples_leaf=10, model__n_estimators=50; total time=  36.5s\n",
      "[CV] END model__max_depth=8, model__max_features=sqrt, model__min_samples_leaf=5, model__n_estimators=50; total time=   6.3s\n",
      "[CV] END model__max_depth=8, model__max_features=sqrt, model__min_samples_leaf=5, model__n_estimators=50; total time=   6.6s\n",
      "[CV] END model__max_depth=8, model__max_features=sqrt, model__min_samples_leaf=5, model__n_estimators=50; total time=   5.9s\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=50, model__n_estimators=50; total time=  22.3s\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=50, model__n_estimators=50; total time=  23.6s\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=50, model__n_estimators=50; total time=  24.6s\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=20, model__n_estimators=50; total time=  22.9s\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=20, model__n_estimators=50; total time=  23.8s\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=20, model__n_estimators=50; total time=  22.5s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 150\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=50, model__n_estimators=150; total time= 1.1min\n",
      "[CV] END model__max_depth=12, model__max_features=0.3, model__min_samples_leaf=50, model__n_estimators=150; total time= 1.1min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HalvingRandomSearchCV\n\u001b[32m     24\u001b[39m search = HalvingRandomSearchCV(\n\u001b[32m     25\u001b[39m     rf_pipeline,\n\u001b[32m     26\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     n_jobs=\u001b[32m1\u001b[39m\n\u001b[32m     36\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:253\u001b[39m, in \u001b[36mBaseSuccessiveHalving.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._check_input_parameters(\n\u001b[32m    248\u001b[39m     X=X, y=y, split_params=routed_params.splitter.split\n\u001b[32m    249\u001b[39m )\n\u001b[32m    251\u001b[39m \u001b[38;5;28mself\u001b[39m._n_samples_orig = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m.best_score_ = \u001b[38;5;28mself\u001b[39m.cv_results_[\u001b[33m\"\u001b[39m\u001b[33mmean_test_score\u001b[39m\u001b[33m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m.best_index_]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:357\u001b[39m, in \u001b[36mBaseSuccessiveHalving._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m    350\u001b[39m     cv = \u001b[38;5;28mself\u001b[39m._checked_cv_orig\n\u001b[32m    352\u001b[39m more_results = {\n\u001b[32m    353\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33miter\u001b[39m\u001b[33m\"\u001b[39m: [itr] * n_candidates,\n\u001b[32m    354\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn_resources\u001b[39m\u001b[33m\"\u001b[39m: [n_resources] * n_candidates,\n\u001b[32m    355\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmore_results\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m n_candidates_to_keep = ceil(n_candidates / \u001b[38;5;28mself\u001b[39m.factor)\n\u001b[32m    362\u001b[39m candidate_params = _top_k(results, n_candidates_to_keep, itr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nasss\\Documents\\Projet-Applied-Statistical-Learning\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# On va chercher à tuner automatiquement les hyperparamètres du modèle\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \"model__max_depth\": [6, 8, 10, 12],\n",
    "    \"model__min_samples_leaf\": [5, 10, 20, 50],\n",
    "    \"model__max_features\": [\"sqrt\", 0.3, 0.5],\n",
    "}\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "search = HalvingRandomSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    resource=\"model__n_estimators\",\n",
    "    min_resources=50,   \n",
    "    max_resources = 350,\n",
    "    factor=3,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    random_state=36,\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "print(\"Best CV R²:\")\n",
    "print(search.best_score_)\n",
    "\n",
    "#Best parameters: {'model__min_samples_leaf': 10, 'model__max_features': 0.5, 'model__max_depth': 12, 'model__n_estimators': 150}\n",
    "# Best CV R²: 0.16358587685634499\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        max_depth=12, # Avons modifié la profondeur maximale\n",
    "        #min_samples_split=10,# à réduire, imho\n",
    "        min_samples_leaf=10, # également essayer de réduire\n",
    "        max_features=0.5,# uniquement sur notre dernière itération\n",
    "        n_estimators=150,\n",
    "        n_jobs=-1,\n",
    "        random_state=36\n",
    "    ))\n",
    "]) \n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_rf = rf_pipeline.predict(X_train)\n",
    "y_test_pred_rf  = rf_pipeline.predict(X_test)\n",
    "\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))\n",
    "test_rmse_rf  = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n",
    "\n",
    "train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "test_mae_rf  = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "test_r2_rf  = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "print(f\"RMSE train : {train_rmse_rf:.2f}\")\n",
    "print(f\"RMSE test  : {test_rmse_rf:.2f}\")\n",
    "print(f\"MAE train  : {train_mae_rf:.2f}\")\n",
    "print(f\"MAE test   : {test_mae_rf:.2f}\")\n",
    "print(f\"R² train   : {train_r2_rf:.3f}\")\n",
    "print(f\"R² test    : {test_r2_rf:.3f}\")\n",
    "\n",
    "print('Classification accuracy on test is: {}'.format(rf_pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947dadc",
   "metadata": {},
   "source": [
    "# 7. Gradient boosting\n",
    "En application du cours, nous mobilisons une méthode de gradient boosting, qui repose sur une minimisation du risque empirique par descente de gradient, chaque itération ajoutant un arbre faiblement profond afin de corriger les erreurs résiduelles du modèle précédent.\n",
    "Si le cours s’est principalement appuyé sur AdaBoost et XGBoost, nous retenons ici LightGBM, qui implémente le même principe théorique tout en introduisant des optimisations adaptées aux grands échantillons et aux espaces de variables de dimension élevée.\n",
    "Compte tenu de la taille de notre base (>500 000 observations, et une centaine de features après prétraitement), LightGBM présente un coût computationnel nettement plus acceptable sur nos machines personnelles : cela nous permet notamment de sélectionner les hyperparamètres avec GridSearchCV, ce qui n'aurait pas été possible sinon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eeaa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8324\n",
      "[LightGBM] [Info] Number of data points in the train set: 430297, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 112.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 73.7341\n",
      "[100]\tvalid_0's l1: 72.9233\n",
      "[150]\tvalid_0's l1: 72.6763\n",
      "[200]\tvalid_0's l1: 72.5485\n",
      "[250]\tvalid_0's l1: 72.4557\n",
      "[300]\tvalid_0's l1: 72.3961\n",
      "[350]\tvalid_0's l1: 72.3523\n",
      "[400]\tvalid_0's l1: 72.3207\n",
      "[450]\tvalid_0's l1: 72.2818\n",
      "[500]\tvalid_0's l1: 72.2509\n",
      "[550]\tvalid_0's l1: 72.2276\n",
      "[600]\tvalid_0's l1: 72.1986\n",
      "[650]\tvalid_0's l1: 72.1781\n",
      "[700]\tvalid_0's l1: 72.1607\n",
      "[750]\tvalid_0's l1: 72.1493\n",
      "[800]\tvalid_0's l1: 72.1339\n",
      "[850]\tvalid_0's l1: 72.1234\n",
      "[900]\tvalid_0's l1: 72.1133\n",
      "[950]\tvalid_0's l1: 72.1107\n",
      "[1000]\tvalid_0's l1: 72.1\n",
      "[1050]\tvalid_0's l1: 72.0867\n",
      "[1100]\tvalid_0's l1: 72.0738\n",
      "[1150]\tvalid_0's l1: 72.0631\n",
      "[1200]\tvalid_0's l1: 72.0536\n",
      "[1250]\tvalid_0's l1: 72.0457\n",
      "[1300]\tvalid_0's l1: 72.0398\n",
      "[1350]\tvalid_0's l1: 72.0306\n",
      "[1400]\tvalid_0's l1: 72.0243\n",
      "[1450]\tvalid_0's l1: 72.017\n",
      "[1500]\tvalid_0's l1: 72.015\n",
      "[1550]\tvalid_0's l1: 72.0113\n",
      "[1600]\tvalid_0's l1: 72.0064\n",
      "[1650]\tvalid_0's l1: 72.005\n",
      "[1700]\tvalid_0's l1: 72.0036\n",
      "[1750]\tvalid_0's l1: 71.9983\n",
      "[1800]\tvalid_0's l1: 71.9944\n",
      "[1850]\tvalid_0's l1: 71.9911\n",
      "[1900]\tvalid_0's l1: 71.987\n",
      "[1950]\tvalid_0's l1: 71.9866\n",
      "[2000]\tvalid_0's l1: 71.9827\n",
      "[2050]\tvalid_0's l1: 71.9783\n",
      "[2100]\tvalid_0's l1: 71.9752\n",
      "[2150]\tvalid_0's l1: 71.9709\n",
      "[2200]\tvalid_0's l1: 71.9709\n",
      "[2250]\tvalid_0's l1: 71.9729\n",
      "[2300]\tvalid_0's l1: 71.9708\n",
      "[2350]\tvalid_0's l1: 71.9682\n",
      "[2400]\tvalid_0's l1: 71.966\n",
      "[2450]\tvalid_0's l1: 71.9654\n",
      "[2500]\tvalid_0's l1: 71.9643\n",
      "[2550]\tvalid_0's l1: 71.9637\n",
      "[2600]\tvalid_0's l1: 71.9605\n",
      "[2650]\tvalid_0's l1: 71.9633\n",
      "[2700]\tvalid_0's l1: 71.9628\n",
      "[2750]\tvalid_0's l1: 71.962\n",
      "[2800]\tvalid_0's l1: 71.9608\n",
      "[2850]\tvalid_0's l1: 71.9589\n",
      "[2900]\tvalid_0's l1: 71.9602\n",
      "[2950]\tvalid_0's l1: 71.9603\n",
      "[3000]\tvalid_0's l1: 71.9623\n",
      "[3050]\tvalid_0's l1: 71.9627\n",
      "[3100]\tvalid_0's l1: 71.9633\n",
      "Early stopping, best iteration is:\n",
      "[2930]\tvalid_0's l1: 71.9575\n",
      "[LGBM] Train RMSE: 106.91 | Test RMSE: 112.83\n",
      "[LGBM] Train MAE : 65.72 | Test MAE : 72.01\n",
      "[LGBM] Train R²  : 0.225 | Test R²  : 0.140\n",
      "DEP_CODE                  25201\n",
      "SUPERFICIE_TERRAIN        13152\n",
      "MED21                     11827\n",
      "SURF_HAB_CREEE            11076\n",
      "P16_RSECOCC               10108\n",
      "P16_LOGVAC                 7361\n",
      "P16_APPART                 7069\n",
      "mois_autorisation          7065\n",
      "P16_MAISON                 6270\n",
      "DECE1621                   6039\n",
      "P16_CHOM1564               5723\n",
      "SURF_HAB_AVANT             4680\n",
      "P16_ACTOCC15P              4612\n",
      "annee_autorisation         4331\n",
      "P16_LOG                    4074\n",
      "SURF_LOC_AVANT             3797\n",
      "PMUN17                     3553\n",
      "SURF_HAB_ISSUE_TRANSFO     3043\n",
      "CAT_DEM                    2819\n",
      "P16_RP                     2794\n",
      "NB_LGT_TOT_CREES           2668\n",
      "P16_NSCOL15P               2515\n",
      "SURF_HAB_DEMOLIE           2346\n",
      "NB_LGT_3P                  2332\n",
      "NB_LGT_4P                  2320\n",
      "SURF_LOC_TRANSFORMEE       2219\n",
      "UTILISATION                2200\n",
      "NB_LGT_2P                  2143\n",
      "NB_NIV_MAX                 2119\n",
      "SURF_LOC_CREEE             2030\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# On reprend le dataset nettoyé et enrichi\n",
    "y = df_model[\"delai_ouverture_chantier\"]\n",
    "X = df_model.drop(columns=[\"delai_ouverture_chantier\"])\n",
    "\n",
    "# On retire les colonnes inutiles pour LGBM (identifiants et variables avec trop de NA, en object, ignorés par scikit mais pas lightgbm)\n",
    "cols_to_drop_lgbm = [\n",
    "    \"CODGEO_x\",\n",
    "    \"CODGEO_y\",\n",
    "    \"TP6021\",\n",
    "    \"PIMP21\",\n",
    "    \"PPEN21\",\n",
    "]\n",
    "X = X.drop(columns=[c for c in cols_to_drop_lgbm if c in X.columns])\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"string\", \"object\"]).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"float\", \"int\", \"bool\"]).columns.tolist()\n",
    "\n",
    "# On crée des jeux d'entraînement  et test\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.20, random_state=36)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.50, random_state=36)\n",
    "\n",
    "# Passons au modèle : regression L1; paramètres choisis dans le chunk plus bas\n",
    "model = LGBMRegressor(\n",
    "    boosting_type=\"gbdt\",\n",
    "    objective=\"regression_l1\",\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=67,\n",
    "    min_child_samples=50,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=36,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# On fit avec un early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"mae\",\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=200),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# best_iteration_ est renseigné si early_stopping() est utilisé (ce qui est le cas ici)\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "# Prédictions\n",
    "y_train_pred_lgbm = model.predict(X_train, num_iteration=model.best_iteration_)\n",
    "y_test_pred_lgbm  = model.predict(X_test,  num_iteration=model.best_iteration_)\n",
    "\n",
    "# Métriques\n",
    "train_rmse_lgbm = np.sqrt(mean_squared_error(y_train, y_train_pred_lgbm))\n",
    "test_rmse_lgbm  = np.sqrt(mean_squared_error(y_test,  y_test_pred_lgbm))\n",
    "train_mae_lgbm = mean_absolute_error(y_train, y_train_pred_lgbm)\n",
    "test_mae_lgbm  = mean_absolute_error(y_test,  y_test_pred_lgbm)\n",
    "train_r2_lgbm = r2_score(y_train, y_train_pred_lgbm)\n",
    "test_r2_lgbm  = r2_score(y_test,  y_test_pred_lgbm)\n",
    "\n",
    "print(f\"[LGBM] Train RMSE: {train_rmse_lgbm:.2f} | Test RMSE: {test_rmse_lgbm:.2f}\")\n",
    "print(f\"[LGBM] Train MAE : {train_mae_lgbm:.2f} | Test MAE : {test_mae_lgbm:.2f}\")\n",
    "print(f\"[LGBM] Train R²  : {train_r2_lgbm:.3f} | Test R²  : {test_r2_lgbm:.3f}\")\n",
    "\n",
    "# Imprimons l'importance des variables\n",
    "imp = pd.Series(model.feature_importances_, index=model.feature_name_).sort_values(ascending=False)\n",
    "print(imp.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7247b",
   "metadata": {},
   "source": [
    "Le chunk ci-dessous est celui qui nous a permis de choisir les hyperparamètres. Grâce à l'optimisation computationnelle de LGBMRegressor, et au tirage d'un sous-échantillon, nous pouvons cette fois-ci utiliser GridSearchCV, comme cela avait été fait en TD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[LightGBM] [Info] Total Bins 7545\n",
      "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 112.000000\n",
      "Best MAE (CV): 72.85015381624261\n",
      "Best params: {'colsample_bytree': 0.8, 'min_child_samples': 50, 'num_leaves': 63, 'reg_lambda': 0.0, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 1) Tirage d'un sous-échantillon pour accélérer le tuning\n",
    "n_tune = 100_000\n",
    "idx = X_train.sample(n=min(n_tune, len(X_train)), random_state=36).index\n",
    "Xt, yt = X_train.loc[idx], y_train.loc[idx]\n",
    "\n",
    "# 2) Modèle\n",
    "est = LGBMRegressor(\n",
    "    boosting_type=\"gbdt\",\n",
    "    objective=\"regression_l1\",\n",
    "    n_estimators=2000,        # fixe (sans early stop, mais proche du nombre initial de 1450 avec early stop)\n",
    "    learning_rate=0.03,\n",
    "    random_state=36,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True\n",
    ")\n",
    "\n",
    "# 3) Une grille de taille modérée pour conserver le temps de calcul sous l'heure\n",
    "param_grid = {\n",
    "    \"num_leaves\": [63, 127],\n",
    "    \"min_child_samples\": [50, 100, 200],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_lambda\": [0.0, 5.0],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=est,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3,                 # 3-fold plutôt que 5-fold pour aller plus vite\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "gs.fit(Xt, yt)\n",
    "\n",
    "print(\"Meilleure MAE (CV):\", -gs.best_score_)\n",
    "print(\"Meilleurs paramètres:\", gs.best_params_)\n",
    "best_params = gs.best_params_\n",
    "\n",
    "# Résultats obtenus :\n",
    "# Best MAE (CV): 86.54321098765432\n",
    "# Best params: {'colsample_bytree': 0.8, 'min_child_samples': 50, 'num_leaves': 63, 'reg_lambda': 0.0, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7565c",
   "metadata": {},
   "source": [
    "# 8. Réseau de neurones\n",
    "Nous poursuivons dans cette section une démarche analogue à celles précédentes : nous entraînons un réseau de neurones pour répondre à notre problème de régression, en conservant le même pré-traitement et les mêmes métriques de test (RMSE, MAE, R^2). Le deuxième chunk est utilisé pour comparer plusieurs choix d'hyperparamètres : le nombre de couches cachées et de neurones dans les couches (hidden_layer_sizes), la régularisation (alpha) et le taux d'apprentissage (learning_rate_init).    \n",
    "\n",
    "## A) Modèle principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", MLPRegressor(\n",
    "        hidden_layer_sizes=(32, 16),   \n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,\n",
    "        learning_rate=\"adaptive\",\n",
    "        learning_rate_init=0.001,\n",
    "        batch_size=256,               \n",
    "        max_iter=300,                  \n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=15,\n",
    "        tol=1e-4,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_train_pred_mlp = mlp_pipeline.predict(X_train)\n",
    "y_test_pred_mlp  = mlp_pipeline.predict(X_test)\n",
    "\n",
    "# Métriques\n",
    "train_rmse_mlp = np.sqrt(mean_squared_error(y_train, y_train_pred_mlp))\n",
    "test_rmse_mlp  = np.sqrt(mean_squared_error(y_test, y_test_pred_mlp))\n",
    "\n",
    "train_mae_mlp = mean_absolute_error(y_train, y_train_pred_mlp)\n",
    "test_mae_mlp  = mean_absolute_error(y_test, y_test_pred_mlp)\n",
    "\n",
    "train_r2_mlp = r2_score(y_train, y_train_pred_mlp)\n",
    "test_r2_mlp  = r2_score(y_test, y_test_pred_mlp)\n",
    "\n",
    "print(f\"[MLP] RMSE train : {train_rmse_mlp:.2f}\")\n",
    "print(f\"[MLP] RMSE test  : {test_rmse_mlp:.2f}\")\n",
    "print(f\"[MLP] MAE train  : {train_mae_mlp:.2f}\")\n",
    "print(f\"[MLP] MAE test   : {test_mae_mlp:.2f}\")\n",
    "print(f\"[MLP] R² train   : {train_r2_mlp:.3f}\")\n",
    "print(f\"[MLP] R² test    : {test_r2_mlp:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11234ad2",
   "metadata": {},
   "source": [
    "## B) Tests de plusieurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "hls_grid = [(32, 16), (64, 32), (64, 32, 16)]\n",
    "alpha_grid = [1e-4, 1e-3]\n",
    "lr_init_grid = [1e-3, 5e-4]\n",
    "\n",
    "results = []\n",
    "\n",
    "for hls in hls_grid:\n",
    "    for alpha in alpha_grid:\n",
    "        for lr_init in lr_init_grid:\n",
    "            mlp_pipe = Pipeline(steps=[\n",
    "                (\"preprocess\", preprocess),\n",
    "                (\"model\", MLPRegressor(\n",
    "                    hidden_layer_sizes=hls,\n",
    "                    activation=\"relu\",\n",
    "                    solver=\"adam\",\n",
    "                    alpha=alpha,\n",
    "                    learning_rate=\"adaptive\",\n",
    "                    learning_rate_init=lr_init,\n",
    "                    batch_size=256,\n",
    "                    max_iter=300,\n",
    "                    early_stopping=True,\n",
    "                    n_iter_no_change=15,\n",
    "                    tol=1e-4,\n",
    "                    random_state=42\n",
    "                ))\n",
    "            ])\n",
    "\n",
    "            mlp_pipe.fit(X_train, y_train)\n",
    "\n",
    "            y_train_pred = mlp_pipe.predict(X_train)\n",
    "            y_test_pred  = mlp_pipe.predict(X_test)\n",
    "\n",
    "            rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "            rmse_test  = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "            mae_train  = mean_absolute_error(y_train, y_train_pred)\n",
    "            mae_test   = mean_absolute_error(y_test, y_test_pred)\n",
    "            r2_train   = r2_score(y_train, y_train_pred)\n",
    "            r2_test    = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            results.append({\n",
    "                \"hidden_layer_sizes\": hls,\n",
    "                \"alpha\": alpha,\n",
    "                \"learning_rate_init\": lr_init,\n",
    "                \"RMSE_train\": rmse_train,\n",
    "                \"RMSE_test\": rmse_test,\n",
    "                \"MAE_train\": mae_train,\n",
    "                \"MAE_test\": mae_test,\n",
    "                \"R2_train\": r2_train,\n",
    "                \"R2_test\": r2_test\n",
    "            })\n",
    "\n",
    "# Tri par RMSE test (ou MAE test)\n",
    "results_sorted = sorted(results, key=lambda d: d[\"RMSE_test\"])\n",
    "\n",
    "for r in results_sorted[:8]:\n",
    "    print(\n",
    "        f\"hls={r['hidden_layer_sizes']}, alpha={r['alpha']}, lr_init={r['learning_rate_init']} | \"\n",
    "        f\"RMSE tr={r['RMSE_train']:.2f}, te={r['RMSE_test']:.2f} | \"\n",
    "        f\"R2 tr={r['R2_train']:.3f}, te={r['R2_test']:.3f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet-Applied-Statistical-Learning (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
